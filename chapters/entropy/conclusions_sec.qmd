# Riflessioni conclusive della sezione {.unnumbered .unlisted}

Questa sezione ha aggiunto al nostro toolkit tre idee chiave:

1. **Entropia (Shannon).** Una misura intrinsecamente probabilistica dell’incertezza: più la distribuzione è “piatta”, più informazione è necessaria per identificare l’esito. Oltre alla definizione formale, abbiamo visto esempi applicativi (stima dai campioni, collegamento alla codifica). 

2. **Divergenza KL.** Una metrica asimmetrica che quantifica il *costo informativo dell’errore di modello*: usare $Q$ quando i dati provengono da $P$ ci fa “spendere” bit extra in media. È il criterio teorico che giustifica perché preferiamo modelli che approssimano bene la generatrice dei dati senza sovra-adattarsi.

3. **Valutazione predittiva bayesiana.** Spostare l’attenzione dall’aderenza in-sample alla *capacità di previsione out-of-sample*: log-score punto-per-punto, *ELPD* come quantità da massimizzare e *LOO-CV/WAIC* come stime pratiche dell’ELPD. In questa cornice, il “modello migliore” è quello che *prevede meglio* nuovi dati, non quello che minimizza il residuo sui dati già visti. 

Il valore aggiunto, per la psicologia, è duplice:

* **Metodologico.** Entropia e KL offrono un linguaggio comune per discutere *incertezza*, *complessità* e *generalizzazione*, coerente con l’uso della distribuzione predittiva posteriore introdotta nei capitoli bayesiani.
* **Pratico.** Gli strumenti come *LOO-CV* e *WAIC* si integrano naturalmente nel flusso di lavoro con `brms`/Stan: stimiamo il modello, calcoliamo l’ELPD, confrontiamo le specificazioni e scegliamo quella che massimizza l’accuratezza predittiva, prevenendo sia underfitting che overfitting. 

In sintesi, questa sezione del libro ha reso esplicito il legame tra *informazione* e *inferenza*: quanto più un modello riduce l’incertezza (in senso predittivo) senza introdurre complessità superflua, tanto più è informativo. Questo prepara il terreno ai capitoli successivi, in cui la scelta e la valutazione dei modelli — anche meccanicistici e dinamici — saranno guidate da criteri *predittivi* e *informazionali*, non solo da adattamenti locali ai dati. 


