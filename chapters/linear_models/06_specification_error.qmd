# Errore di specificazione e bias da variabile omessa {#sec-omitted-variable}

::: {.epigraph}

> “The coefficients may be useful for descriptive purposes, but not for causal inference or even prediction.”
>
> — **David A. Freedman**, From Association to Causation via Regression
:::

## Introduzione {.unnumbered .unlisted}

Finora abbiamo presentato la regressione lineare come uno strumento potente e flessibile per descrivere relazioni tra variabili. Abbiamo visto come stimarne i parametri, come interpretarli e come implementarli sia in R che in Stan. Ma in tutte queste applicazioni abbiamo dato per scontato un punto cruciale: che il modello fosse *specificato correttamente*.

Nella pratica, questa condizione è raramente soddisfatta. Può accadere che una variabile rilevante non sia stata inclusa nel modello, oppure che la forma funzionale ipotizzata non descriva adeguatamente la relazione reale. In questi casi parliamo di *errore di specificazione del modello*.

Una delle conseguenze più importanti è il cosiddetto *bias da variabile omessa*: quando trascuriamo un predittore correlato sia con la variabile dipendente sia con altri predittori inclusi, le stime dei coefficienti risultano distorte. Questo non è un dettaglio tecnico, ma un problema sostanziale: potremmo attribuire a un predittore un effetto che in realtà appartiene a un altro, fraintendendo così i meccanismi che hanno generato i dati.

In questo capitolo analizzeremo cosa significa errore di specificazione, mostreremo matematicamente come nasce il bias da variabile omessa e discuteremo le sue implicazioni nella ricerca psicologica. Comprendere questi limiti è fondamentale non solo per interpretare in modo corretto i risultati della regressione, ma anche per formulare modelli più adeguati e consapevoli.

### Panoramica del capitolo {.unnumbered .unlisted}

* Bias da variabile omessa: escludere una variabile rilevante altera sistematicamente i coefficienti.
* Condizioni del bias.
* Implicazioni: i coefficienti OLS non sono interpretabili in chiave causale; la regressione è *fenomenologica*.
* Prospettiva: privilegiare modelli meccanicistici (es., Rescorla–Wagner, DDM, dinamici EMA).

::: {.callout-tip collapse=true}
## Prerequisiti

Per seguire al meglio questo capitolo è utile avere:

- una conoscenza di base della *regressione lineare semplice* e del concetto di coefficiente di regressione.
:::

::: {.callout-caution collapse=true title="Preparazione del Notebook"}

```{r}
#| output: false
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(brms, posterior, cmdstanr, tidybayes, loo, patchwork)
```
:::


## Errore di specificazione e bias da variabile omessa {#sec-ovb}

### Idea chiave

Se il *vero* modello è

$$
Y=\beta_0+\beta_1X_1+\beta_2X_2+\varepsilon,\qquad \mathbb{E}[\varepsilon\mid X_1,X_2]=0,
$$
ma stimiamo erroneamente il modello che *omette* $X_2$,

$$
Y=\alpha_0+\alpha_1X_1+u,
$$
allora il coefficiente su $X_1$ risulta distorto quando:

1. $X_2$ ha *effetto diretto* su $Y$ ($\beta_2\neq 0$);
2. $X_2$ è *correlata* con $X_1$ ($\mathrm{Corr}(X_1,X_2)\neq 0$).


### Dimostrazione (via standardizzazione)

#### Passo 1 — Standardizza le variabili

Definiamo medie $\mu_1,\mu_2,\mu_Y$ e deviazioni standard $\sigma_1,\sigma_2,\sigma_Y$. Poniamo

$$
Z_1=\frac{X_1-\mu_1}{\sigma_1},\qquad 
Z_2=\frac{X_2-\mu_2}{\sigma_2},\qquad
Z_Y=\frac{Y-\mu_Y}{\sigma_Y}.
$$

Per costruzione: 

- $\mathrm{Var}(Z_1)=\mathrm{Var}(Z_2)=1$, 
- $\mathrm{Cov}(Z_1,Z_2)=\rho_{12}=\mathrm{Corr}(X_1,X_2)$.

Il *modello vero standardizzato* è

$$
Z_Y=\gamma_1 Z_1+\gamma_2 Z_2+\varepsilon_z,\qquad \mathbb{E}[\varepsilon_z\mid Z_1,Z_2]=0,
$$
con *beta standardizzati*

$$
\gamma_1=\beta_1\,\frac{\sigma_1}{\sigma_Y},\qquad
\gamma_2=\beta_2\,\frac{\sigma_2}{\sigma_Y}.
$$

#### Passo 2 — Stima (erronea) che omette $Z_2$

Stimiamo la regressione univariata

$$
Z_Y=\delta_1 Z_1 + \text{errore}.
$$

Per OLS,

$$
\hat\delta_1=\frac{\mathrm{Cov}(Z_1,Z_Y)}{\mathrm{Var}(Z_1)}=\mathrm{Cov}(Z_1,Z_Y),
$$
dato che $\mathrm{Var}(Z_1)=1$.

Usiamo il modello vero standardizzato:

$$
\begin{align}
\mathrm{Cov}(Z_1,Z_Y)
&=\mathrm{Cov}\big(Z_1,\gamma_1Z_1+\gamma_2Z_2+\varepsilon_z\big)\notag\\
&=\gamma_1\underbrace{\mathrm{Var}(Z_1)}_{=1}
+\gamma_2\,\mathrm{Cov}(Z_1,Z_2)
+\underbrace{\mathrm{Cov}(Z_1,\varepsilon_z)}_{=0}.
\end{align} 
$$

Quindi

$$
\boxed{\;\hat\delta_1=\gamma_1+\gamma_2\,\rho_{12}\;}.
$$

**Lettura immediata:** il coefficiente stimato univariato mescola l’effetto diretto standardizzato di $X_1$ ($\gamma_1$) con un termine spurio $\gamma_2\rho_{12}$ dovuto all’omissione di $X_2$.


### Ritraduzione ai coefficienti non standardizzati

Tra i coefficienti vale

$$
\hat\delta_1=\frac{\sigma_1}{\sigma_Y}\,\hat\alpha_1,\qquad
\gamma_1=\beta_1\,\frac{\sigma_1}{\sigma_Y},\qquad
\gamma_2=\beta_2\,\frac{\sigma_2}{\sigma_Y}.
$$

Dalla formula standardizzata

$$
\hat\delta_1=\gamma_1+\gamma_2\rho_{12}
$$
segue

$$
\frac{\sigma_1}{\sigma_Y}\,\hat\alpha_1
=\beta_1\frac{\sigma_1}{\sigma_Y}
+\beta_2\frac{\sigma_2}{\sigma_Y}\rho_{12}.
$$

Moltiplicando per $\sigma_Y/\sigma_1$ e ricordando che
$\rho_{12}=\dfrac{\mathrm{Cov}(X_1,X_2)}{\sigma_1\sigma_2}$,
ottieniamo la forma non standardizzata:

$$
\boxed{\;\hat\alpha_1=\beta_1+\beta_2\,\frac{\mathrm{Cov}(X_1,X_2)}{\mathrm{Var}(X_1)}\;}.
$$

**Bias (in media):**

$$
\boxed{\;\mathbb{E}[\hat\alpha_1]-\beta_1
=\beta_2\,\frac{\mathrm{Cov}(X_1,X_2)}{\mathrm{Var}(X_1)}\;}
\quad\Longleftrightarrow\quad
\boxed{\;\mathbb{E}[\hat\delta_1]-\gamma_1=\gamma_2\rho_{12}\;}.
$$



### Interpretazione didattica

* **Condizioni per il bias:** serve *sia* $\beta_2\neq 0$ (l’omessa $X_2$ conta davvero su $Y$) *sia* $\rho_{12}\neq 0$ (l’omessa $X_2$ è correlata con $X_1$). Se una condizione manca, il bias svanisce.
* **Segno del bias (scala standardizzata):** $\mathrm{Bias}(\hat\delta_1)=\gamma_2\rho_{12}$.
  - $\gamma_2>0$ e $\rho_{12}>0$ ⇒ *sovrastima*; 
  - $\gamma_2>0$ e $\rho_{12}<0$ ⇒ *sottostima*.


### Perché conta in psicologia

La regressione multipla è un modello *fenomenologico*: fotografa *associazioni* tra variabili, non i *meccanismi* che le generano. In contesti psicologici, l’*omissione di variabili rilevanti* è spesso inevitabile: non conosciamo o non misuriamo tutti i determinanti di $Y$. Ne segue che i coefficienti parziali possono essere *sistematicamente distorti* e, dunque, fuorvianti.


### Oltre la regressione: modelli formali dei processi

Per queste ragioni, i modelli di regressione multipla dovrebbero avere un ruolo limitato in psicologia. Molto più promettente è l’uso di *modelli formali* che cercano di rappresentare i meccanismi psicologici sottostanti. Esempi discussi in questa dispensa sono:

- il *modello di apprendimento di Rescorla–Wagner*, che spiega come gli individui aggiornano le loro aspettative sulla base del feedback;  
- il *Drift Diffusion Model (DDM)*, che descrive i processi decisionali come un accumulo di evidenza nel tempo;  
- i *modelli dinamici per dati EMA*, che mostrano come l’umore e altre variabili psicologiche cambiano nel tempo.  

Questi modelli non si limitano a descrivere correlazioni, ma cercano di catturare i *processi causali* che generano i dati osservati.


::: {.callout-tip collapse=true title="1) Mappa del bias: variazione di $\rho_{12}$ e $\beta_2$"}
Esaminiamo come **segno** e **magnitudo** del bias cambino al variare della correlazione tra regressori ($\rho_{12}$) e dell’effetto dell’omessa ($\beta_2$). La heatmap visualizza $\hat\alpha_1-\beta_1$.

```{r}
#| message: false
set.seed(1)
n <- 3000; beta1 <- 1; sig <- 1
rho_seq <- seq(-.9,.9,length=19); b2_seq <- seq(-1.5,1.5,length=19)

grid <- expand.grid(rho=rho_seq, b2=b2_seq)

sim_once <- function(rho, beta2){
  X1 <- rnorm(n)
  X2 <- rho*X1 + sqrt(1-rho^2)*rnorm(n)   # Corr(X1,X2)=rho
  Y  <- beta1*X1 + beta2*X2 + rnorm(n,0,sig)
  coef(lm(Y ~ X1))[2] - beta1             # ritorna uno scalare, senza nome
}

grid$bias <- mapply(sim_once, grid$rho, grid$b2)  # <-- niente t(), niente [, "bias"]

ggplot(grid, aes(x=rho, y=b2, fill=bias)) +
  geom_tile() + scale_fill_gradient2() +
  labs(x=expression(rho[12]), y=expression(beta[2]), fill="Bias",
       title="Bias da variabile omessa al variare di ρ12 e β2")
```

**Commento e interpretazione.**
L’asse orizzontale riporta la correlazione tra i regressori $\rho_{12}=\mathrm{Corr}(X_1,X_2)$; l’asse verticale l’effetto dell’omessa $X_2$ su $Y$ ($\beta_2$). Il riempimento (“Bias”) è $\hat\alpha_1-\beta_1$, cioè di quanto il coefficiente sul regressore incluso $X_1$ *sovrastima* (valori > 0) o *sottostima* (valori < 0) il suo valore vero.

* **Segno del bias.** Il bias è (in media) $\beta_2\,\rho_{12}$.
  Quadranti:
  
  - $\beta_2>0,\ \rho_{12}>0$ → **positivo** (sovrastima);
  - $\beta_2>0,\ \rho_{12}<0$ → **negativo** (sottostima);
  - $\beta_2<0,\ \rho_{12}>0$ → **negativo**;
  - $\beta_2<0,\ \rho_{12}<0$ → **positivo**.
  
  Le bande di colore cambiano segno attraversando le linee $\rho_{12}=0$ o $\beta_2=0$, dove il bias si annulla (zona chiara).

* **Magnitudo.** Aumenta con $|\beta_2|$ e $|\rho_{12}|$: gli angoli (|ρ|≈0.9, |β₂|≈1.5) mostrano i *bias maggiori*. La diagonale basso-sinistra → alto-destra evidenzia bias *positivo*; l’altra diagonale bias *negativo*.

* **Simmetria e teoria.** La mappa è sostanzialmente simmetrica perché il bias teorico è $\beta_2\rho_{12}$. Le piccole irregolarità dipendono dal rumore Monte Carlo della simulazione (con $n$ finito). 

* **Lettura pratica.** Se *anche solo una* tra correlazione tra regressori ($\rho_{12}$) o effetto dell’omessa ($\beta_2$) è prossima a zero, il bias è trascurabile (aree chiare lungo gli assi). Quando *entrambi* sono lontani da zero, l’OLS nel modello omesso è *fuorviante*.

:::

## Riflessioni conclusive {.unnumbered .unlisted}

In questo capitolo abbiamo visto come la validità delle stime di regressione dipenda in modo cruciale dalla corretta specificazione del modello. Abbiamo discusso in particolare il *bias da variabile omessa*, mostrando che trascurare un predittore rilevante può distorcere i coefficienti degli altri, inducendo interpretazioni fuorvianti.

Questo non è un problema marginale: nella ricerca psicologica capita spesso di lavorare con costrutti complessi, difficili da misurare, e di non poter includere tutte le variabili rilevanti. In queste condizioni, le stime di regressione rischiano di riflettere relazioni spurie piuttosto che effetti reali. Essere consapevoli di questi limiti è quindi essenziale per interpretare i risultati con cautela e per progettare studi che riducano al minimo il rischio di specificare modelli inadeguati.

La lezione più importante è che la regressione, come ogni modello fenomenologico, non deve essere scambiata per una spiegazione causale: è un modo per descrivere associazioni nei dati, che può però facilmente indurre in errore se non viene accompagnato da una riflessione critica sulla struttura del modello.

Nel prossimi capitolo vedremo come l’ANOVA a una via possa essere interpretata come un caso particolare del modello lineare. Sarà l’occasione per consolidare ulteriormente la visione unificata che guida questa sezione: regressione e confronto tra gruppi non sono strumenti separati, ma facce diverse dello stesso impianto metodologico.

::: {.callout-note collapse=true title="Informazioni sull'ambiente di sviluppo"}
```{r}
sessionInfo()
```
:::


## Bibliografia {.unnumbered .unlisted}
