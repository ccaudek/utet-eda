{
  "hash": "d72831b878fd849502d5844ec31c73a3",
  "result": {
    "engine": "knitr",
    "markdown": "# Dalla descrizione alla spiegazione {#sec-key-notions-cogn-models}\n\n::: {.epigraph}\n> “We know from first principles that no causal query can be answered from data alone, without causal information that lies outside the data. No causes in – no causes out.”\n>\n> — **Judea Pearl**, Can DAGs do the un-doable? (2018) \n:::\n\n\n## Introduzione \n\nPer comprendere e spiegare i processi mentali in modo più rigoroso, è necessario adottare modelli che vadano oltre la semplice descrizione. Questo capitolo introduce i modelli meccanicistici e computazionali, mostrando come possano rafforzare la spiegazione psicologica. Negli ultimi anni, la psicologia ha attraversato una crisi profonda legata alla *riproducibilità* dei risultati sperimentali. Molti effetti classici non riescono a replicarsi in studi successivi, sollevando interrogativi sulla solidità delle teorie psicologiche. In questo contesto, è sempre più chiaro che il tipo di modelli utilizzati per spiegare i fenomeni psicologici ha un impatto cruciale sulla credibilità e robustezza della ricerca scientifica. Una distinzione centrale a questo riguardo è quella tra *modelli fenomenologici* e *modelli meccanicistici*. \n\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n* Il ruolo dei modelli computazionali nella psicologia scientifica.\n* La struttura e la logica di due modelli fondamentali — il modello di Rescorla-Wagner (per l’apprendimento associativo) e il Drift Diffusion Model (per le decisioni sotto incertezza).\n\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Consulta *Why is the Rescorla-Wagner model so influential?* [@soto2023rescorla].\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(rtdists)\n```\n:::\n\n:::\n\n\n### Modelli fenomenologici: descrivere senza spiegare\n\nI modelli fenomenologici si limitano a descrivere relazioni osservabili tra variabili psicologiche, spesso attraverso formule matematiche o rappresentazioni statistiche. Un esempio classico è una legge psicofisica che descrive la relazione tra stimolazione sensoriale e risposta percepita. Sebbene questi modelli possano essere estremamente predittivi, non forniscono informazioni sul \"come\" e \"perché\" un certo fenomeno si verifica. Non specificano, cioè, *le entità e le attività organizzate che lo generano* (es. meccanismi cognitivi, neuroni, moduli funzionali).\n\nCome sottolineato da @povich_mechanistic_2025, modelli fenomenologici come questi possono essere *accurati*, *compatti*, persino *predittivi* — ma non necessariamente *esplicativi*. In effetti, possono mancare della capacità di rispondere a domande controfattuali del tipo “che cosa succederebbe se…?” e non permettono un controllo diretto sul fenomeno. Questa limitazione si rivela particolarmente problematica in un’epoca in cui la replicabilità richiede non solo constatare un effetto, ma anche comprenderne le condizioni causali e contestuali.\n\n\n### Dai modelli meccanicistici alla modellazione computazionale\n\nUn *modello meccanicistico* cerca di rappresentare le componenti causali di un fenomeno. Secondo una definizione ampiamente condivisa, un meccanismo è “una collezione organizzata di entità e attività che produce o mantiene un certo fenomeno” [@bechtel2009looking]. I modelli meccanicistici hanno l’obiettivo di descrivere questi meccanismi, specificando in che modo le componenti interagiscono per generare il comportamento osservato.\n\nNel contesto della psicologia, i modelli meccanicistici vanno oltre la descrizione di correlazioni osservabili. Cercano di identificare strutture cognitive, processi neurali o dinamiche corpo-ambiente o interazioni tra livelli (funzionale, computazionale, implementazionale). Un esempio ben noto è il modello della *long-term potentiation* (LTP) nella memoria, che spiega come variazioni nei recettori NMDA e AMPA e nella concentrazione di ioni calcio e magnesio determinano il rafforzamento sinaptico — un chiaro caso di spiegazione meccanicistica.\n\nOggi, molti modelli meccanicistici in psicologia sono implementati come modelli computazionali, ovvero rappresentazioni formali che simulano i processi interni ipotizzati. Attraverso la simulazione e la stima dei parametri, questi modelli permettono di inferire il funzionamento dei meccanismi sottostanti a partire dal comportamento osservabile. I modelli computazionali soddisfano i criteri della spiegazione meccanicistica quando forniscono informazioni su entità ipotetiche (come credenze, soglie decisionali, accumulo di evidenza) e sulle loro interazioni causali.\n\n\n### La differenza epistemica: come distinguere spiegazione da predizione\n\nUn punto chiave nella distinzione tra spiegazioni fenomenologiche e meccanicistiche è che solo le seconde soddisfano i criteri di *potere esplicativo* propriamente detto. Come chiarisce @povich_mechanistic_2025, un modello esplicativo deve permettere di:\n\n* rispondere a domande controfattuali (*\"che cosa succederebbe se una componente fosse diversa?\"*);\n* fornire la base per manipolare o controllare il fenomeno.\n\nQuesti criteri sono cruciali per superare la crisi della replicabilità: sapere che un effetto si verifica in certe condizioni è poco utile se non si capisce *perché* avviene e *quali sono i meccanismi* sottostanti che lo rendono stabile o instabile rispetto a cambiamenti contestuali.\n\n\n### Oltre le metafore meccaniche: che cosa rende *meccanicistico* un modello?\n\nUna fonte comune di confusione riguarda l’idea che un modello, per essere *meccanicistico*, debba avere necessariamente la forma di una macchina, con entità concrete (es. neuroni, aree cerebrali) e connessioni visibili tra di esse. Ma questa è una semplificazione fuorviante. Ciò che rende un modello *meccanicistico* non è la sua forma visiva o metaforica, ma la sua capacità di rappresentare *l’organizzazione causale del processo* che genera un certo comportamento. Un modello può essere espresso con equazioni matematiche, algoritmi, reti neurali, simulazioni, eppure contribuire in modo decisivo a una spiegazione meccanicistica se *specifica in che modo le componenti del sistema interagiscono per produrre l’effetto osservato*.\n\nPer chiarire questa idea, possiamo richiamare i tre livelli di spiegazione proposti da David Marr (1982), uno dei riferimenti fondamentali nella psicologia cognitiva computazionale:\n\n* *Livello computazionale*: *Cosa* fa il sistema e *perché* (qual è il problema che risolve?).\n* *Livello algoritmico*: *Come* lo fa? Quali rappresentazioni interne e quali trasformazioni (regole di calcolo) sono coinvolte.\n* *Livello implementativo*: *Con quali mezzi fisici* è realizzato (per esempio, circuiti neurali).\n\nQuesta distinzione aiuta a chiarire che un modello può essere meccanicistico anche se non rappresenta direttamente substrati biologici, purché descriva in modo formale come un sistema risolve un problema e quali regole seguono le sue componenti.\n\nNel contesto della psicologia, i modelli computazionali che operano al *livello algoritmico o computazionale* — come il modello di Rescorla-Wagner o il Drift Diffusion Model — sono perfettamente coerenti con un approccio meccanicistico, anche se non rappresentano esplicitamente l’implementazione biologica.\n\nQuesti modelli sono “meccanicistici” nel senso che:\n\n* *descrivono entità funzionali* (es. valore atteso, evidenza accumulata),\n* *specificano regole di interazione* tra queste entità (es. aggiornamento, accumulo, soglie),\n* *producono il comportamento osservabile* come risultato di queste interazioni.\n\nDunque, ciò che conta non è la *forma* del modello, ma la *funzione esplicativa* che svolge all’interno della teoria psicologica. Modelli formulati come sistemi dinamici, modelli bayesiani gerarchici, modelli di reti neurali artificiali o modelli simbolici possono tutti contribuire a spiegazioni meccanicistiche, se mostrano come un certo comportamento emerga da un’organizzazione di componenti in interazione.\n\n\n### Perché i modelli meccanicistici rafforzano la riproducibilità\n\nLa crisi della riproducibilità può essere vista come il sintomo di un’eccessiva fiducia in modelli fenomenologici che mancano di profondità esplicativa. I modelli meccanicistici, al contrario:\n\n* esplicitano gli assunti causali e strutturali;\n* permettono verifiche controfattuali e manipolazioni;\n* chiariscono quando e perché un effetto dovrebbe ripetersi o variare;\n* sono meno vulnerabili al *cherry picking* e agli *effetti di contesto* non dichiarati;\n* i modelli computazionali meccanicistici, come il DDM e il modello di Rescorla-Wagner, consentono di simulare e verificare quantitativamente ipotesi sui meccanismi interni, rendendo più trasparente e replicabile l’inferenza psicologica.\n\nIn breve, un modello meccanicistico non si limita a dire che “A predice B”, ma mostra come *A produce B*, e in quali condizioni questo accade.\n\n\n<!-- ## Esempi di modelli computazionali meccanicistici -->\n\n<!-- Nel contesto della psicologia cognitiva e della neuroscienza computazionale, molti modelli meccanicistici assumono la forma di modelli computazionali. Questi modelli non si limitano a correlare input e output, ma simulano i processi interni che trasformano gli input (es. stimoli) in output (es. risposte comportamentali), ipotizzando una dinamica causale tra variabili latenti e osservabili. -->\n\n\n<!-- ### Il modello di Rescorla-Wagner: apprendimento associativo come aggiornamento predittivo -->\n\n<!-- Uno dei modelli più influenti nello studio dell'apprendimento è il modello di Rescorla-Wagner. Questo modello descrive come gli individui apprendano le associazioni tra stimoli e risposte sulla base dell'errore di previsione. L'apprendimento avviene aggiornando le aspettative di ricompensa in base alle esperienze passate, utilizzando due parametri fondamentali: -->\n\n<!-- - *$\\alpha$ (tasso di apprendimento)*: determina quanto l'errore di previsione influisce sull'aggiornamento dell'aspettativa. -->\n<!-- - *$\\beta$ (temperatura della scelta)*: regola la probabilità di selezionare l'opzione con il valore atteso più alto rispetto a esplorare alternative. -->\n\n<!-- #### L'apprendimento associativo -->\n\n<!-- L'apprendimento per rinforzo studia come le persone imparano a massimizzare le ricompense in ambienti in cui la scelta ottimale è inizialmente sconosciuta. Immaginiamo un partecipante che deve scegliere ripetutamente tra due slot machine, ricevendo ricompense con probabilità diverse per ogni macchina. L'obiettivo è massimizzare le vincite nel tempo. -->\n\n<!-- Per illustrare il modello, si usa spesso la metafora delle slot machine. Nel caso più semplice, si immagina un agente che svolge il compito con $n$ tentativi, due slot machine e probabilità di ricompensa fisse $\\mu = [0.2, 0.8]$. -->\n\n<!-- #### Regola di apprendimento per rinforzo ($\\delta$-rule) -->\n\n<!-- Il modello di Rescorla-Wagner descrive l'apprendimento come un processo basato sull'errore di previsione. L'aggiornamento del valore di uno stimolo avviene secondo la seguente equazione: -->\n\n<!-- $$ -->\n<!-- V_{s,t} = V_{s,t-1} + \\alpha (r_{t-1} - V_{s,t-1}) -->\n<!-- $$ -->\n\n<!-- dove: -->\n\n<!-- - $V_{s,t}$ è il valore atteso dello stimolo $s$ al tempo $t$. -->\n<!-- - $r_{t-1}$ è la ricompensa ottenuta alla prova precedente. -->\n<!-- - $\\alpha$ (tra 0 e 1) è il tasso di apprendimento, che determina la velocità con cui l'agente aggiorna le proprie aspettative. -->\n\n<!-- Se il valore di $\\alpha$ è alto, l'apprendimento sarà rapido, mentre se è basso, l'agente si baserà maggiormente sulle esperienze passate. -->\n\n<!-- #### Modello di scelta Softmax -->\n\n<!-- Dopo aver aggiornato i valori attesi delle opzioni, il partecipante deve scegliere tra esse. -->\n\n<!-- Due strategie possibili sono: -->\n\n<!-- - *sfruttamento*: selezionare sempre l'opzione con il valore più alto; -->\n<!-- - *esplorazione*: scegliere occasionalmente un'opzione con un valore più basso per verificare se potrebbe essere migliore. -->\n\n<!-- Per modellare questo comportamento si usa la funzione Softmax: -->\n\n<!-- $$ -->\n<!-- p(s) = \\frac{\\exp(\\beta \\cdot V_{s})}{\\sum_i \\exp(\\beta \\cdot V_{i})}, -->\n<!-- $$ -->\n\n<!-- dove $\\beta$ è un parametro che determina il grado di esplorazione: -->\n\n<!-- - $\\beta = 0$: scelta completamente casuale. -->\n<!-- - $\\beta \\to \\infty$: scelta deterministica dell'opzione con il valore più alto. -->\n\n<!-- Un individuo con $\\beta$ alto sceglierà quasi sempre l'opzione con il valore atteso più elevato, mentre con un $\\beta$ basso esplorerà più frequentemente. -->\n\n\n<!-- #### Simulazione dell'apprendimento con il modello di Rescorla-Wagner -->\n\n<!-- Possiamo ora simulare questo processo in R. La funzione seguente implementa la regola di aggiornamento dell’aspettativa sulla base dell’errore di previsione: -->\n\n<!-- ```{r} -->\n<!-- update_rw <- function(value, alpha=0.15, lambda=1) { -->\n<!--   value + alpha * (lambda - value) -->\n<!-- } -->\n<!-- ``` -->\n\n<!-- Simuliamo ora l'apprendimento per 40 prove, assumendo che il partecipante riceva sempre una ricompensa: -->\n\n<!-- ```{r} -->\n<!-- n_trials <- 40 -->\n<!-- strength <- numeric(n_trials) -->\n<!-- for(trial in 2:n_trials) { -->\n<!--   strength[trial] <- update_rw(strength[trial-1]) -->\n<!-- } -->\n<!-- plot(1:n_trials, strength, type = 'l', ylim = c(0,1), xlab = \"Prove\", ylab = \"Aspettativa di ricompensa\") -->\n<!-- ``` -->\n\n<!-- L'aspettativa di ricompensa aumenta progressivamente fino a stabilizzarsi. -->\n\n\n<!-- #### Estinzione dell'associazione -->\n\n<!-- Modificando il valore del rinforzo, possiamo anche simulare l’estinzione dell’apprendimento. Se dopo 25 prove la ricompensa non viene più fornita, il valore associato allo stimolo diminuisce gradualmente: -->\n\n<!-- ```{r} -->\n<!-- n_trials <- 50                 -->\n<!-- strength <- numeric(n_trials) -->\n<!-- lambda <- 1 -->\n\n<!-- for(trial in 2:n_trials) { -->\n<!--   if(trial > 25) { -->\n<!--     lambda <- 0 -->\n<!--   } -->\n<!--   strength[trial] <- update_rw(value = strength[trial-1], lambda = lambda) -->\n<!-- } -->\n\n<!-- plot(1:n_trials, strength, type = 'l', ylim = c(0,1), xlab = \"Prove\", ylab = \"Aspettativa di ricompensa\") -->\n<!-- ``` -->\n\n<!-- L'associazione si estingue gradualmente quando il rinforzo viene rimosso. -->\n\n\n<!-- #### Implementazione della regola Softmax -->\n\n<!-- Per simulare le scelte di un partecipante utilizziamo la funzione Softmax: -->\n\n<!-- ```{r} -->\n<!-- softmax <- function(beta, x) { -->\n<!--   1 / (1 + exp(-beta * x)) -->\n<!-- } -->\n\n<!-- beta <- 5 -->\n<!-- x <- seq(-1, 1, length.out = 100) -->\n<!-- y <- softmax(beta, x) -->\n<!-- plot(x, y, type = 'l', xlab = \"Valore (A) - valore (B)\", ylab = \"p(scelta = A)\") -->\n<!-- ``` -->\n\n<!-- La funzione mostra che: -->\n\n<!-- 1. la probabilità di scegliere un'opzione aumenta con il suo valore atteso; -->\n<!-- 2. con $\\beta$ elevato, il partecipante sceglie quasi sempre l'opzione migliore; -->\n<!-- 3. con $\\beta$ basso, le scelte sono più casuali. -->\n\n\n<!-- #### Verifica e applicazioni del modello -->\n\n<!-- Quello descritto è il meccanismo generatore dei dati ipotizzato dal modello di Rescorla-Wagner. Per testare il modello, è necessario stimare i parametri $\\alpha$ e $\\beta$, e confrontare le previsioni del modello con i dati osservati. Tuttavia, in questo corso non affronteremo il problema della stima dei parametri del modello di Rescorla-Wagner. L'obiettivo principale è comprendere cosa significhi formalizzare quantitativamente un modello psicologico e in che modo questo approccio si differenzi da una semplice analisi delle associazioni tra variabili. -->\n\n<!-- In sintesi, il modello di Rescorla-Wagner rappresenta uno strumento essenziale per lo studio dell'apprendimento associativo. Attraverso la simulazione dell'aggiornamento delle aspettative e delle strategie decisionali, possiamo descrivere il comportamento di individui che apprendono in contesti di rinforzo. Questo modello ha trovato applicazione in numerosi ambiti della psicologia cognitiva e delle neuroscienze, contribuendo alla comprensione dei processi di apprendimento e decisione. -->\n\n\n<!-- ### Il Drift Diffusion Model (DDM) -->\n\n<!-- Il processo decisionale è uno dei temi centrali della psicologia cognitiva e delle neuroscienze. Ogni giorno prendiamo decisioni, dalle più semplici alle più complesse, influenzate da fattori come la percezione, la memoria, l’attenzione e il contesto in cui ci troviamo. Una domanda fondamentale è: *Come prendiamo decisioni in condizioni di incertezza?*   -->\n\n<!-- Uno dei modelli più utilizzati per rispondere a questa domanda è il *Drift Diffusion Model (DDM)*, un modello matematico che descrive il processo di accumulo delle informazioni fino alla presa di una decisione. Questo modello consente di quantificare e comprendere i meccanismi alla base delle scelte umane. -->\n\n\n<!-- #### Cos’è il Drift Diffusion Model? -->\n\n<!-- Il DDM descrive come le persone raccolgono informazioni nel tempo per prendere una decisione tra due alternative. Immagina di dover stabilire se un punto si sta muovendo verso destra o verso sinistra. Non hai una risposta immediata, ma accumuli informazioni (o \"evidenza\") nel tempo fino a quando non sei abbastanza sicuro per scegliere.   -->\n\n<!-- Questo processo è influenzato da vari fattori, come la chiarezza delle prove disponibili e l’incertezza associata alla decisione. -->\n\n<!-- #### Come funziona il processo di accumulo dell’evidenza? -->\n\n<!-- Il processo decisionale può essere paragonato a un *accumulo graduale di informazioni* a favore di una delle due opzioni disponibili. Ecco come funziona: -->\n\n<!-- 1. *Raccolta delle informazioni.* Ogni nuova informazione che ricevi si accumula a favore di una delle due alternative. Ad esempio, se stai cercando di determinare la direzione del movimento di un punto, ogni piccolo dettaglio visivo ti aiuta ad avvicinarti a una decisione. -->\n\n<!-- 2. *Velocità di accumulo (Drift rate).* La velocità con cui raccogli le informazioni dipende dalla qualità del segnale. Se le prove sono chiare e forti, l’accumulo sarà veloce. Se invece sono ambigue, il processo sarà più lento. -->\n\n<!-- 3. *Rumore e incertezza.* Durante l’accumulo, c’è sempre una componente casuale o \"rumore\", che può causare fluttuazioni nel processo. Questo significa che l’informazione non si accumula in modo perfettamente lineare, ma può oscillare a causa di fattori casuali. -->\n\n<!-- 4. *Soglie decisionali.* Prima di iniziare il compito, ci sono due \"soglie\" che rappresentano i punti di decisione. Quando l’evidenza accumulata raggiunge una di queste soglie, si prende la decisione corrispondente. -->\n\n<!-- 5. *Tempo di reazione.* Il tempo impiegato per raggiungere una delle soglie è il *tempo di reazione*. Se le informazioni sono chiare, la decisione sarà rapida; se sono ambigue, il tempo sarà più lungo. -->\n\n<!-- Una metafora utile per comprendere questo processo è quella di *un secchio che si riempie goccia dopo goccia*: ogni informazione raccolta corrisponde a una goccia. Quando il livello d’acqua supera una soglia, si prende la decisione. -->\n\n\n<!-- #### I parametri del DDM -->\n\n<!-- Il DDM è caratterizzato da quattro parametri principali che descrivono diversi aspetti del processo decisionale. -->\n\n<!-- 1. *Tasso di drift ($v$).* Rappresenta la velocità con cui l’evidenza si accumula a favore di una decisione. Valori più alti indicano un processo decisionale più efficiente, mentre valori più bassi suggeriscono un’accumulazione lenta e incerta. -->\n\n<!-- 2. *Separazione delle soglie ($a$).* Indica la distanza tra le due soglie decisionali. Valori più alti corrispondono a decisioni più caute (tempi di reazione più lunghi ma minore probabilità di errore), mentre valori più bassi indicano decisioni più rapide ma potenzialmente meno accurate. -->\n\n<!-- 3. *Tempo di non-decisione ($t_0$).* Corrisponde al tempo necessario per processi che precedono e seguono l’accumulo di evidenza, come la percezione dello stimolo e l’esecuzione della risposta. Questo tempo è indipendente dall’accumulo delle informazioni. -->\n\n<!-- 4. *Bias iniziale ($z$).* Definisce il punto di partenza del processo di accumulo. Se è equidistante tra le due soglie, la decisione è imparziale. Se invece è spostato verso una delle due soglie, significa che la persona ha una predisposizione a scegliere una delle due alternative. -->\n\n\n<!-- #### Il compromesso tra velocità e accuratezza -->\n\n<!-- Uno degli aspetti più interessanti del DDM è il *compromesso tra velocità e accuratezza*: -->\n\n<!-- - se una persona desidera rispondere rapidamente, può *abbassare le soglie decisionali*, ma questo aumenta la probabilità di errore;   -->\n<!-- - se invece punta a una maggiore accuratezza, può *aumentare la distanza tra le soglie*, rendendo il processo più lento ma più affidabile. -->\n\n<!-- Questo compromesso è evidente in compiti sperimentali come:   -->\n\n<!-- - il *compito di Stroop*, dove bisogna ignorare un’informazione interferente (es. leggere il colore di una parola e non il significato della parola stessa);   -->\n<!-- - il *compito di decisione lessicale*, in cui si deve determinare se una stringa di lettere è una parola esistente o meno.   -->\n\n<!-- Il DDM permette di capire se le differenze nei tempi di reazione tra gruppi dipendono da una strategia più cauta (maggiore $a$) o da una difficoltà nell’accumulare evidenza (minore $v$). -->\n\n\n<!-- #### Perché è importante il DDM? -->\n\n<!-- Il DDM è uno strumento potente perché permette di *quantificare* aspetti del processo decisionale che altrimenti sarebbero difficili da misurare, come la velocità di accumulo dell’evidenza o l’effetto del rumore sulla decisione.   -->\n\n<!-- È stato applicato in numerosi ambiti, tra cui: -->\n\n<!-- - *compiti percettivi e decisionali*: studi sulla discriminazione di stimoli visivi e uditivi; -->\n<!-- - *processi di controllo cognitivo*: analisi delle differenze individuali nella regolazione dell’impulsività; -->\n<!-- - *psicopatologia*: esplorazione delle alterazioni nel processo decisionale in condizioni come depressione, ansia e schizofrenia. -->\n\n<!-- Il *Drift Diffusion Model* offre dunque una rappresentazione chiara e quantitativa del processo decisionale in condizioni di incertezza. Descrivendo l’accumulo graduale delle informazioni e il raggiungimento delle soglie decisionali, il modello ci aiuta a comprendere il compromesso tra velocità e accuratezza e i fattori che influenzano le scelte.   -->\n\n<!-- L’applicazione del DDM in psicologia cognitiva e neuroscienze permette di studiare non solo il comportamento umano, ma anche i meccanismi neurali che regolano il processo decisionale. -->\n\n\n<!-- #### Simulazione del DDM -->\n\n<!-- Una delle potenzialità del DDM è la possibilità di simulare dati sintetici per confrontare le predizioni del modello con dati empirici. In R, possiamo generare una simulazione semplificata del modello utilizzando pacchetti dedicati come `rtdists` o `brms`.  -->\n\n<!-- Un esempio di codice per simulare dati con parametri definiti: -->\n\n<!-- ```{r} -->\n<!-- # Nuova configurazione dei parametri -->\n<!-- a <- 1.2   # Separazione delle soglie (aumentato) -->\n<!-- v <- 0.3   # Tasso di drift -->\n<!-- t0 <- 0.2  # Tempo di non-decisione -->\n<!-- z <- 0.5   # Bias iniziale (deve essere tra 0 e 1) -->\n\n<!-- # Generazione dei dati -->\n<!-- sim_data <- rdiffusion(n = 1000, a = a, v = v, t0 = t0, z = z) -->\n<!-- ``` -->\n\n<!-- Questa funzione genera 1000 decisioni simulate, ciascuna con un tempo di reazione (rt) e una risposta (response) che dipendono dai parametri impostati. -->\n\n<!-- ```{r} -->\n<!-- # Visualizzazione dei tempi di reazione -->\n<!-- hist( -->\n<!--   sim_data$rt,  -->\n<!--   breaks = 30,  -->\n<!--   main = \"Distribuzione dei tempi di reazione\",  -->\n<!--   xlab = \"RT (s)\" -->\n<!-- ) -->\n<!-- ``` -->\n\n<!-- Questo codice genera una distribuzione di tempi di reazione e scelte coerenti con le ipotesi del DDM, permettendo di esplorare l'effetto delle variazioni dei parametri sul comportamento del modello. -->\n\n<!-- In sintesi, il Drift Diffusion Model fornisce un quadro teorico potente per l'analisi del processo decisionale in psicologia cognitiva. Modellando il tempo di reazione e la probabilità di risposta in termini di parametri interpretabili, il DDM permette di distinguere tra strategie decisionali e difficoltà cognitive, superando i limiti di un'analisi puramente descrittiva. Grazie alla sua capacità di catturare la dinamica dei processi decisionali, il DDM è oggi uno degli strumenti più utilizzati per studiare il comportamento umano in contesti sperimentali e applicativi. -->\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nLa crisi di replicabilità che caratterizza la psicologia contemporanea impone un ripensamento metodologico profondo, orientato verso un superamento dei modelli puramente descrittivi a favore di paradigmi meccanicistici e computazionali. A differenza dei primi, questi ultimi non si limitano a prevedere esiti comportamentali, ma mirano a identificare i processi algoritmici e i meccanismi latenti che li generano, trasformando così domande di ricerca generiche in ipotesi formalizzate e rigorosamente verificabili.\n\nL’adozione di un approccio computazionale in psicologia cognitiva consente di ovviare ai limiti intrinseci dell’analisi descrittiva, offrendo un quadro matematico solido per valutare ipotesi sui processi mentali. L’integrazione di modelli di apprendimento e modelli decisionali, in particolare, permette di costruire rappresentazioni unificate e più profonde dei sistemi cognitivi che sottendono il comportamento umano, con ricadute significative sia nella ricerca di base che in ambito applicativo e clinico.\n\nTale prospettiva si colloca organicamente nel quadro emergente della psichiatria computazionale e della modellazione bayesiana della cognizione, il cui scopo ultimo non è meramente descrittivo, ma inferenziale: individuare quali processi interni risultino più plausibili alla luce dei dati osservati. In questo senso, la formalizzazione computazionale non migliora soltanto il potere esplicativo dei modelli, ma potenzia anche la capacità di inferenza e generalizzazione, due componenti fondamentali per lo sviluppo di una scienza psicologica cumulativa, robusta e realmente replicabile.\n\n<!-- In questo capitolo abbiamo introdotto due modelli fondamentali: il modello Rescorla-Wagner e il modello Drift Diffusion model.  -->\n\n<!-- Il modello di Rescorla-Wagner illustra come l'apprendimento associativo derivi da un aggiornamento incrementale delle aspettative, guidato dall'errore di previsione. La sua forza risiede nella capacità di quantificare parametri psicologicamente significativi, come il tasso di apprendimento (α), che riflette la sensibilità individuale alle discrepanze tra aspettative e realtà. L'aggiunta della funzione softmax permette di modellare il conflitto tra esplorazione e sfruttamento, catturando la variabilità adattiva del comportamento. -->\n\n<!-- Parallelamente, il Drift Diffusion Model (DDM) scompone la decisione in un processo dinamico di accumulo di evidenza, in cui parametri come la velocità di elaborazione (drift rate), la cautela decisionale (threshold separation) e i tempi non decisionali (non-decision time) permettono di distinguere componenti cognitive diverse. Questo approccio supera le descrizioni statiche, rivelando come diverse strategie emergano dall'interazione tra vincoli computazionali e contesto. -->\n\n<!-- Entrambi i modelli evidenziano il valore della formalizzazione matematica nello studio dei processi cognitivi. Il modello di Rescorla-Wagner è particolarmente utile per comprendere come gli individui apprendano e aggiornino le proprie credenze sulla base dell'esperienza, mentre il DDM fornisce una rappresentazione più dettagliata delle dinamiche della presa di decisione e del compromesso tra velocità e accuratezza. -->\n\n::: {.callout-important collapse=\"true\" title=\"Problemi\" }\n\n1. Che cosa descrive il modello di Rescorla-Wagner?\n2. Qual è il ruolo del parametro α nel modello di Rescorla-Wagner? \n3. Quale funzione matematica viene utilizzata per modellare il bilanciamento tra esplorazione ed esploitazione nel modello di Rescorla-Wagner?\n4. Quali sono i principali parametri del Drift Diffusion Model (DDM)? \n5. In che modo il DDM spiega il compromesso tra velocità e accuratezza nelle decisioni? \n\n:::\n\n::: {.callout-tip title=\"Soluzioni\" collapse=\"true\"}\n\n1. Il modello di Rescorla-Wagner descrive come gli individui apprendano le associazioni tra stimoli e risposte in base all’errore di previsione. L’aspettativa di ricompensa viene aggiornata attraverso l’esperienza, con un processo regolato dal tasso di apprendimento ($\\alpha$). \n\n2. Il parametro $\\alpha$ (tasso di apprendimento) determina quanto velocemente un individuo aggiorna le proprie aspettative in base all’errore di previsione. Se $\\alpha$ è alto, l’apprendimento è rapido; se è basso, l’individuo si basa maggiormente sulle esperienze passate.\n\n3. La funzione Softmax viene utilizzata per modellare il bilanciamento tra esplorazione e sfruttamento. Essa regola la probabilità di scegliere un’opzione in base al valore atteso e alla temperatura della scelta ($\\beta$).  \n\n4. I principali parametri del DDM sono:\n\n   - *tasso di drift ($v$)*: velocità con cui viene accumulata l’evidenza; \n   - *separazione delle soglie ($a$)*: distanza tra le soglie decisionali;  \n   - *tempo di non-decisione ($t_0$)*: tempo impiegato per processi indipendenti dall’accumulo dell’evidenza;  \n   - *bias iniziale ($z$)*: punto di partenza dell’accumulo dell’evidenza.  \n\n5. Il DDM spiega il compromesso tra velocità e accuratezza attraverso la separazione delle soglie decisionali ($a$). Se le soglie sono più vicine, le decisioni sono più rapide ma meno accurate; se sono più distanti, le decisioni sono più lente ma più precise.  \n:::\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] rtdists_0.11-5        pillar_1.11.0         tinytable_0.13.0     \n#>  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#>  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [25] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#> [10] vctrs_0.6.5           gsl_2.1-8             stringr_1.5.1        \n#> [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#> [16] backports_1.5.0       rmarkdown_2.29        ragg_1.5.0           \n#> [19] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#> [22] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#> [25] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#> [28] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#> [31] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#> [34] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#> [37] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#> [40] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#> [43] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#> [46] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#> [49] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#> [52] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#> [55] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#> [58] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#> [61] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#> [64] nlme_3.1-168          cli_3.6.5             evd_2.3-7.1          \n#> [67] textshaping_1.0.3     expm_1.0-0            svUnit_1.0.8         \n#> [70] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#> [73] digest_0.6.37         msm_1.8.2             TH.data_1.1-4        \n#> [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#> [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}