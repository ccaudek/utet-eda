{
  "hash": "0eda5534fb5969d6ab2579d1788123e6",
  "result": {
    "engine": "knitr",
    "markdown": "# Causalità dai dati osservazionali {#sec-eda-causality}\n\n::: {.epigraph}\n> “To understand causation is not merely to describe regularities, but to imagine what would happen under interventions.”\n>\n> -- **Judea Pearl**, *Causality* (2009)\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nQuando in psicologia ci chiediamo *perché* un fenomeno si verifica, stiamo entrando nel territorio della *causalità*. Per esempio: l’esposizione a situazioni di stress causa davvero un aumento dei sintomi depressivi? Oppure si tratta solo di una correlazione, magari dovuta a un terzo fattore che non abbiamo considerato?\n\nQuesta distinzione tra *correlazione* e *causalità* è fondamentale: \n\n- la correlazione ci dice che due variabili variano insieme;  \n- la causalità implica invece che una variabile *produce* un cambiamento nell’altra.  \n\nIn psicologia e nelle scienze sociali non possiamo quasi mai fare esperimenti perfettamente controllati, come avviene in laboratorio nelle scienze naturali. Per questo motivo, abbiamo bisogno di strumenti teorici e statistici che ci aiutino a ragionare in termini causali anche quando i dati provengono da studi osservativi.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Il problema della causalità in assenza di esperimenti.\n- I quattro confondenti fondamentali (catena, biforcazione, collider, discendente).\n- Le inferenze dai dati osservazionali.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/). Focalizzati sul capitolo 1 *The Golem of Prague*. \n- Leggere *Causal inference with observational data and unobserved confounding variables* di @byrnes2024causal.\n- Leggere *Causal design patterns for data anal$Y$sts* [@riedererdesignpatterns]. Questo post sul blog fornisce una panoramica di diversi approcci per fare affermazioni causali dai dati osservazionali.\n- Leggere [The Effect: An Introduction to Research Design and Causality](https://theeffectbook.net). Focalizzati sul capitolo 10 *Treatment Effects*.\n- Leggere [Causal Inference](https://mixtape.scunning.com/03-directed_acyclical_graphs) di Scott Cunningham. Focalizzati sul capitolo 3 *Directed Acyclic Graphs*.\n- Leggere *Telling Stories with Data* [@alexander2023telling]. Concentrati sul capitolo 15 *Causalit$Y$ from observational data*.\n:::\n\n::: {.callout-tip collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\nconflicts_prefer(ggplot2::theme_void)\n```\n:::\n\n:::\n\n\n## Il ruolo dei modelli\n\nImmaginiamo di osservare che studenti che dormono poco tendono a riportare più ansia.  Possiamo dire che *dormire poco causa ansia*? Oppure è possibile che *l’ansia causi insonnia*?  O magari entrambe le variabili sono influenzate da un terzo fattore, ad esempio *periodi di esami universitari*? Questo semplice esempio mostra che i dati da soli non bastano: dobbiamo avere un modello teorico che ci guidi nell’interpretazione.\n\nI modelli statistici ci aiutano a formalizzare queste ipotesi causali:\n\n- un modello puramente descrittivo si limita a dire che due variabili sono associate;  \n- un modello causale, invece, esplicita ipotesi su *come* e *perché* una variabile influenza un’altra.\n\nLo scopo di questo capitolo è introdurre alcuni strumenti concettuali di base per distinguere tra correlazione e causalità e per capire come i modelli possano essere usati in psicologia per affrontare domande causali.\n\n\n## Correlazione non significa causalità\n\nUno degli errori più comuni in psicologia è confondere la correlazione con la causalità.  Se due variabili si muovono insieme, non significa necessariamente che una sia la causa dell’altra.\n\n### Esempio classico\n\nSupponiamo di osservare che, durante l’estate, aumenta sia il consumo di gelati sia il numero di persone che hanno colpi di calore.  È forse il *consumo di gelati* a causare i colpi di calore?  Oppure sono i *colpi di calore* a spingere le persone a mangiare più gelati?  La risposta, ovviamente, è che entrambe le variabili sono influenzate da un *fattore esterno*: la temperatura. Il caldo estivo aumenta sia la voglia di gelato sia il rischio di colpo di calore.  \n\n\n### Un esempio psicologico\n\nDurante i periodi d’esame universitari aumentano sia lo *stress* sia i *disturbi del sonno*. Dobbiamo concludere che lo stress causa direttamente insonnia?  Oppure che l’insonnia genera stress?  La spiegazione più plausibile è che entrambe le variabili dipendano da un *fattore esterno comune*: la pressione del contesto degli esami.  \n\nQuesta situazione, in cui due variabili sono legate da una causa comune, si chiama *confondimento*.\n\n### Perché è importante in psicologia\n\nNegli studi psicologici, spesso osserviamo correlazioni interessanti: ad esempio, tra uso dei social media e benessere psicologico.  Ma senza un *modello causale*, non possiamo dire se:  \n\n- sono i social media a ridurre il benessere,  \n- se chi ha meno benessere tende a usare di più i social,  \n- oppure se entrambe le cose dipendono da un terzo fattore, come la solitudine.\n\n### La lezione da ricordare\n\nLa correlazione è un punto di partenza utile, ma non basta per stabilire una relazione di causa-effetto. Per andare oltre, dobbiamo introdurre strumenti che ci aiutino a *rappresentare e testare ipotesi causali*, come vedremo nelle sezioni successive.\n\n\n## Rappresentare le relazioni causali\n\nPer ragionare in modo chiaro sulle relazioni di causa-effetto è utile avere un linguaggio formale.  Uno degli strumenti più potenti a questo scopo è rappresentare le relazioni tra variabili con un *grafo causale*.\n\n### Che cos’è un grafo causale\n\nUn grafo causale è un diagramma formato da:  \n\n- *nodi*, che rappresentano le variabili di interesse (ad esempio: stress, ansia, sonno);  \n- *frecce*, che indicano ipotesi di influenza causale (ad esempio: lo stress → ansia).\n\nQuesti grafi non sono semplici figure illustrative: sono veri e propri *modelli* che esplicitano le nostre ipotesi su come le variabili si influenzano.\n\n\n### Un esempio psicologico\n\nImmaginiamo di voler studiare il legame tra stress e rendimento universitario.  Possiamo proporre un grafo causale come questo:\n\n- Stress → Qualità del sonno → Rendimento agli esami  \n\nQui stiamo ipotizzando che lo stress riduca la qualità del sonno, e che a sua volta un sonno peggiore abbassi il rendimento. In altre parole, il sonno agisce da *variabile mediatore*.\n\n\n### Perché è utile\n\nRappresentare i dati in questo modo ci permette di: \n\n1. distinguere tra relazioni dirette e indirette.  \n2. chiarire il ruolo di possibili variabili di confondimento.  \n3. progettare meglio i nostri studi (per esempio, decidere quali variabili misurare per testare una certa ipotesi).\n\n### Un avvertimento\n\nUn grafo causale non ci dice automaticamente quale ipotesi è vera: rappresenta solo ciò che *crediamo* sia plausibile.  Sta poi ai dati e alle analisi statistiche confermare o mettere in discussione queste ipotesi.\n\n\n## Confondimento, mediazione e altre relazioni causali\n\nNei modelli causali non tutte le variabili hanno lo stesso ruolo. È importante distinguere tra diversi tipi di relazioni, perché ognuna porta a interpretazioni diverse.\n\n\n### Variabili di confondimento\n\nUna *variabile di confondimento* è una variabile che influenza sia la presunta causa sia l’effetto.  Se non la consideriamo, rischiamo di attribuire una relazione causale dove in realtà non c’è.\n\n**Esempio.**\nOsserviamo che gli studenti che usano più spesso i social media riportano più sintomi depressivi.  Potremmo pensare che siano i social media a causare depressione.  Ma un possibile *confondente* è la *solitudine*: gli studenti più soli potrebbero usare di più i social e allo stesso tempo sentirsi più depressi.  Se non teniamo conto della solitudine, rischiamo di trarre conclusioni errate.\n\n\n### Variabili mediatrici\n\nUna *variabile mediatrice* è invece un “anello di passaggio” nella catena causale. Non distorce la relazione, ma la spiega.\n\n**Esempio.**\nStress → Qualità del sonno → Ansia.  Qui il sonno media l’effetto dello stress sull’ansia: lo stress peggiora il sonno, e il cattivo sonno aumenta l’ansia.\n\n\n### Variabili moderatrici\n\nUn’altra distinzione utile è quella delle *variabili moderatrici*: fattori che non spiegano la relazione, ma ne modificano la forza o la direzione.\n\n**Esempio.**\nL’effetto dello stress sull’ansia potrebbe essere più forte negli studenti al primo anno rispetto a quelli degli anni successivi.  Qui l’“anno di corso” agisce da moderatore.\n\nCapire se una variabile è un confondente, un mediatore o un moderatore è fondamentale per interpretare correttamente i dati psicologici e per costruire modelli causali realistici.\n\n\n### Le quattro configurazioni fondamentali nei DAG\n\nPer capire bene come funzionano i grafi causali, è utile conoscere le *quattro strutture di base* con cui due variabili possono essere collegate attraverso una terza.\n\n1. **Catena (chain)**  \n   $X \\rightarrow Z \\rightarrow Y$  \n   Qui $Z$ è un *mediatore*: trasmette l’effetto di $X$ su $Y$.  \n   - Se non controlliamo per $Z$, $X$ e $Y$ appaiono correlati.  \n   - Se controlliamo per $Z$, l’effetto di $X$ su $Y$ “scompare”, perché passa interamente da $Z$.\n\n2. **Biforcazione (fork)**  \n   $X \\leftarrow Z \\rightarrow Y$  \n   Qui $Z$ è un *confondente*: causa sia $X$ che $Y$.  \n   - Se non controlliamo per $Z$, vediamo una correlazione spuriosa tra $X$ e $Y$.  \n   - Se controlliamo per $Z$, la correlazione spuria scompare.\n\n3. **Collider**  \n   $X \\rightarrow Z \\leftarrow Y$  \n   Qui $Z$ è un *effetto comune* di $X$ e $Y$.  \n   - Se non controlliamo per $Z$, $X$ e $Y$ sono indipendenti.  \n   - Se invece controlliamo per $Z$ (o per un suo discendente), creiamo artificialmente una correlazione spuriosa.\n\n4. **Discendente**  \n   $X \\rightarrow Y \\rightarrow Z$  \n   Qui $Z$ è un *discendente* di $Y$: porta informazioni sull’effetto di $X$, ma non va confuso con un confondente.  \n   - Controllare un discendente può introdurre bias, perché significa “tagliare” il percorso naturale della causalità.  \n\n\n#### Perché è importante\n\nQueste quattro configurazioni sono le “mattonelle di base” con cui si costruiscono tutti i DAG più complessi. Capire quando conviene controllare una variabile (catena, fork) e quando invece *non bisogna farlo* (collider, discendente) è essenziale per evitare errori nell’inferenza causale.\n\n\n## Dai grafi causali all’inferenza statistica\n\nFinora abbiamo visto che i grafi causali servono a rappresentare le nostre ipotesi.  Ma come possiamo collegarli ai dati e verificare se un modello causale è plausibile?\n\n### Indipendenze e dipendenze\n\nUn’idea chiave è che un grafo causale non descrive solo “chi influenza chi”, ma implica anche certe *relazioni di indipendenza* tra le variabili.  \nQueste relazioni sono importanti perché ci permettono di confrontare il grafo con i dati: se le indipendenze predette non si verificano, il grafo non può essere corretto.\n\n\n#### Esempio 1: Catena (mediazione)\n\nSupponiamo di ipotizzare che:  Stress → Sonno → Ansia. Qui il sonno media l’effetto dello stress sull’ansia.  Se *non* conosciamo il livello di sonno, stress e ansia risulteranno correlati.  Ma *condizionando* sul sonno, lo stress non ci dà più informazioni aggiuntive sull’ansia.  \n\nIn termini statistici:\n\n$$\n\\text{Ansia} \\;\\perp\\!\\!\\!\\perp\\; \\text{Stress} \\mid \\text{Sonno}\n$$\n\n\n#### Esempio 2: Fork (causa comune)\n\nConsideriamo ora:  Sonno → Stress; Sonno → Ansia. Qui il sonno è un *confondente*: influenza sia stress che ansia.  Se non controlliamo per il sonno, vediamo una correlazione spuriosa tra stress e ansia.  Se invece condizioniamo sul sonno, questa correlazione scompare.  \n\nFormalmente anche qui:  \n\n$$\n\\text{Ansia} \\;\\perp\\!\\!\\!\\perp\\; \\text{Stress} \\mid \\text{Sonno}\n$$\n\n\n#### Esempio 3: Collider (effetto comune)\n\nOra immaginiamo:  Stress → Ansia ← Sonno. Qui l’ansia è un *collider*, cioè un effetto comune di stress e sonno.  In questo caso accade l’opposto:  \n\n- senza condizionare su ansia, stress e sonno sono indipendenti;  \n- se invece controlliamo per ansia (o per una sua conseguenza), introduciamo artificialmente una correlazione spuriosa.  \n\nFormalmente:  \n\n$$\n\\text{Stress} \\;\\perp\\!\\!\\!\\perp\\; \\text{Sonno} \\quad \\text{ma non} \\quad \\text{Stress} \\;\\perp\\!\\!\\!\\perp\\; \\text{Sonno} \\mid \\text{Ansia}\n$$\n\n\n### Tabella riassuntiva\n\n| Struttura | Forma | Relazione tra $X$ e $Y$ | Dopo aver controllato $Z$ |\n|-----------|-------|-------------------------|---------------------------|\n| **Catena** (mediazione) | $X \\to Z \\to Y$ | Dipendenti | Indipendenti |\n| **Fork** (causa comune) | $X \\leftarrow Z \\to Y$ | Dipendenti (spuria) | Indipendenti |\n| **Collider** (effetto comune) | $X \\to Z \\leftarrow Y$ | Indipendenti | Dipendenti (spuri) |\n\n\n### Le quattro configurazioni nei DAG \n\nDi seguito trovi quattro figure minime che illustrano *Catena*, *Fork*, *Collider* e *Discendente*.  \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Quattro configurazioni base dei DAG: Catena, Fork, Collider, Discendente.](09_causality_files/figure-html/fig-dag-quad-1.png){#fig-dag-quad fig-align='center' width=85%}\n:::\n:::\n\n\n\n::: {.callout-tip}\n## Errore comune: controllare i collider!\n\n- **Collider**: struttura $X \\to Z \\leftarrow Y$.  \n  - Senza controllare $Z$: $X$ e $Y$ sono *indipendenti*.  \n  - *Controllando $Z$* (o un suo *discendente*): si *crea* una correlazione spuriosa tra $X$ e $Y$.\n\n**Morale pratica**:  \n- Con *catena* e *fork* conviene spesso controllare $Z$ (per rimuovere associazioni non causali o isolare l’effetto diretto).  \n- Con i *collider* (e loro discendenti) *non* bisogna controllare $Z$: si introduce bias invece di rimuoverlo.\n:::\n\n\n### Perché è importante\n\nQuesti esempi mostrano che il significato di *indipendenza condizionata* dipende dalla struttura del grafo.  In pratica:  \n\n- con catene e fork, condizionare “rompe” la correlazione;  \n- con i collider, condizionare la crea.  \n\nSapere in quali casi conviene controllare una variabile e in quali no è essenziale per fare inferenza causale corretta.\n\n\n### Come si verifica l’indipendenza condizionata?\n\nCon i dati, possiamo testare questa ipotesi in diversi modi:\n\n- *Correlazioni parziali*: calcoliamo la correlazione tra stress e ansia *tenendo costante* il sonno.  \n  Se il modello è corretto, questa correlazione dovrebbe essere vicina a zero.  \n- *Regressioni multiple*: stimiamo una regressione dell’ansia sia sullo stress che sul sonno.  \n  Se il grafo è corretto, una volta incluso il sonno nel modello, lo stress non dovrebbe più avere un effetto sull’ansia.  \n- *Test di indipendenza condizionata* (nei metodi più avanzati): procedure statistiche apposite che verificano se due variabili sono indipendenti, dati certi controlli.\n\n\n### Perché è importante\n\nQuesto collegamento tra *grafi causali* e *indipendenze nei dati* è il cuore dell’inferenza causale:  \n\n- i grafi rappresentano le nostre *ipotesi teoriche*, \n- le indipendenze condizionali ci dicono se i dati sono *compatibili* con quelle ipotesi.  \n\nSe un grafo predice un’indipendenza che nei dati non si verifica, dobbiamo concludere che il grafo (cioè la nostra ipotesi causale) è sbagliato o incompleto.\n\n\n### Da ricordare\n\nQuando diciamo che servono *metodi statistici appropriati*, intendiamo proprio questi strumenti (correlazioni parziali, regressioni multiple, test di indipendenza) che ci permettono di confrontare le previsioni del grafo con i dati.  In questo modo, il linguaggio dei DAG non resta un esercizio astratto, ma diventa un *ponte concreto* tra teoria psicologica e analisi empirica. In pratica, per gli psicologi, questo significa imparare a usare strumenti come regressioni multiple, correlazioni parziali e modelli di equazioni strutturali: tutti metodi che mettono alla prova le previsioni implicite dei grafi causali.\n\n\n## Come studiare la causalità in psicologia\n\nAbbiamo visto che i grafi causali aiutano a rappresentare le ipotesi e che i dati possono confermarle o metterle in dubbio.  Ma come si fa, concretamente, a studiare la causalità in psicologia?\n\n### Esperimenti controllati\n\nIl metodo più forte per stabilire una relazione causale è l’*esperimento*.  In un esperimento:\n\n- i partecipanti vengono assegnati in modo casuale a due o più gruppi (randomizzazione);  \n- solo alcuni gruppi ricevono la manipolazione sperimentale (per esempio: una tecnica di rilassamento);\n- si confrontano i risultati nei diversi gruppi.  \n\nGrazie alla randomizzazione, eventuali differenze iniziali tra i gruppi vengono “bilanciate”. In questo modo, se emergono differenze negli esiti, possiamo attribuirle con buona sicurezza alla manipolazione.\n\n\n### Quasi-esperimenti\n\nSpesso però, in psicologia, non possiamo randomizzare i partecipanti.  Per esempio: non possiamo decidere chi subisce un trauma o chi sviluppa un disturbo.  In questi casi si ricorre ai *quasi-esperimenti*, in cui cerchiamo di avvicinarci il più possibile alla logica sperimentale usando:\n\n- gruppi di confronto selezionati con attenzione,  \n- misure ripetute prima e dopo un evento,  \n- tecniche statistiche per ridurre le differenze iniziali tra gruppi.\n\n\n### Studi osservativi\n\nInfine, gran parte della ricerca psicologica si basa su *studi osservativi*, in cui registriamo ciò che accade naturalmente, senza manipolare nulla.  Qui il problema del confondimento è particolarmente serio: dobbiamo usare modelli statistici e controlli accurati per cercare di distinguere tra correlazione e causalità.\n\n\nIn sintesi, possiamo dire che:  \n\n- gli esperimenti sono lo strumento più solido per l’inferenza causale,  \n- i quasi-esperimenti sono un compromesso utile quando la randomizzazione non è possibile,  \n- gli studi osservativi richiedono grande cautela e modelli ben costruiti per trarre conclusioni causali.  \n\n\n## Strategie statistiche per affrontare il confondimento\n\nQuando non possiamo condurre esperimenti, dobbiamo cercare di “imitare” le condizioni sperimentali con strumenti statistici.  Queste tecniche non eliminano del tutto il problema del confondimento, ma ci aiutano a ridurne l’impatto.\n\n### Regressione\n\nIl metodo più semplice e diffuso è la *regressione*.  Inserendo nella regressione variabili che potrebbero agire come confondenti, possiamo stimare l’effetto di una variabile indipendente “a parità di” altre condizioni.  \n\n**Esempio**: se vogliamo studiare l’effetto dell’uso dei social media sul benessere psicologico, possiamo includere anche la solitudine come predittore. In questo modo, l’effetto stimato dei social media sarà corretto per le differenze di solitudine tra le persone.\n\n### Matching\n\nUn’altra strategia è il *matching*: si confrontano persone simili tra loro per tutte le caratteristiche rilevanti, tranne che per la variabile di interesse.  Per esempio, possiamo confrontare studenti che usano molto i social con altri che li usano poco, ma che sono simili per età, genere, rendimento scolastico e livello di solitudine.\n\n### Variabili strumentali\n\nQuando una variabile di confondimento non è osservata o non può essere misurata, anche i metodi di regressione non bastano.  In questi casi, una possibile strategia è usare una *variabile strumentale* (IV, *instrumental variable*).\n\n#### Cos’è una variabile strumentale?\n\nUna variabile $Z$ è un buon strumento per stimare l’effetto di $X$ su $Y$ se rispetta due condizioni:\n\n1. *Rilevanza*: $Z$ influenza $X$.  \n2. *Esogeneità*: $Z$ non influenza $Y$ direttamente, né è correlata con i confondenti di $X$ e $Y$.\n\nIn altre parole, lo strumento agisce come una “fonte di variazione casuale” di $X$, che possiamo sfruttare per stimare il suo effetto su $Y$.\n\n#### Perché serve?\n\nImmagina di voler stimare l’effetto delle *ore di sonno* ($X$) sul *rendimento a un test* ($Y$).  Il problema è che la motivazione ($U$) è un confondente: studenti più motivati tendono a dormire meglio *e* a ottenere voti più alti. Se non possiamo misurare la motivazione, la regressione non ci aiuta.\n\n#### Come interviene lo strumento\n\nSupponiamo di scoprire che il *rumore notturno vicino alla residenza universitaria* ($Z$) influenza quante ore di sonno gli studenti riescono a fare ($X$), ma non influisce direttamente sul loro rendimento ($Y$).  \n\n- $Z$ → influenza il sonno ($X$).  \n- $Z$ non ha effetti diretti su rendimento, né è legato alla motivazione ($U$).  \n\nIn questo caso, il rumore agisce come *strumento*: possiamo usare la variazione di sonno “indotta dal rumore” per stimare l’effetto causale del sonno sul rendimento.\n\n\n#### Da ricordare\n\n- Le variabili strumentali sono molto potenti, ma *difficili da trovare*: serve una variabile che influenzi solo la causa e non l’effetto.  \n- Quando c’è, però, ci permette di “simulare” un esperimento naturale, isolando una fonte quasi-casuale di variazione nella variabile di interesse.\n\nNella pratica psicologica, strumenti così puliti sono rari: l’idea serve più a capire il principio che a trovare sempre uno strumento perfetto.\n\n\nQueste tecniche non sostituiscono l’esperimento, ma rappresentano strumenti preziosi per trarre conclusioni causali quando siamo limitati a dati osservativi.\n\n\n## Un esempio numerico di confondimento\n\nImmaginiamo di voler stimare se lo *studio pomeridiano* ($X$) migliora il *rendimento a un test* ($Y$). Supponiamo però che esista una variabile di confondimento: la *motivazione* ($U$).\n\n- Gli studenti molto motivati tendono sia a studiare più spesso nel pomeriggio ($X$), sia ad avere voti più alti ($Y$).  \n- Se non controlliamo per la motivazione, potremmo concludere che il semplice studiare nel pomeriggio causi voti migliori.\n\nEcco dei dati simulati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 200\nmotivazione <- rbinom(n, 1, 0.5) # 0 = bassa, 1 = alta\nstudio <- rbinom(n, 1, 0.3 + 0.4*motivazione) # più motivati studiano più spesso\nrendimento <- rbinom(n, 1, 0.2 + 0.5*motivazione) # motivazione influenza il voto\n\ntable(studio, rendimento)\n#>       rendimento\n#> studio  0  1\n#>      0 52 43\n#>      1 45 60\n```\n:::\n\n\nSe confrontiamo il rendimento *senza considerare la motivazione*, otteniamo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprop.table(table(studio, rendimento), 1)\n#>       rendimento\n#> studio     0     1\n#>      0 0.547 0.453\n#>      1 0.429 0.571\n```\n:::\n\n\nSembra che chi studia nel pomeriggio abbia risultati migliori. Ma in realtà, l’effetto non dipende dallo studio, bensì dalla *motivazione*, che è il vero fattore causale. Solo controllando per $U$ (ad esempio con una regressione) possiamo separare l’effetto reale da quello spurio.\n\n### Cosa impariamo\n\nQuesto esempio numerico mostra in pratica ciò che i *DAG* ci aiutano a visualizzare:  \n\n- quando esiste una *variabile di confondimento* (come la motivazione), si crea un percorso “indiretto” tra la causa ipotizzata ($X$, lo studio) e l’effetto ($Y$, il rendimento);  \n- questo percorso indiretto può dare l’illusione di un effetto causale anche quando non c’è.  \n\nIn letteratura, questi percorsi indesiderati sono chiamati *percorsi back-door*: collegamenti che partono “da dietro” la variabile di interesse ($X$) e portano a $Y$ passando per un’altra variabile.  \n\nPer ottenere una stima corretta dell’effetto causale, dobbiamo *bloccare* questi percorsi, cioè tenerne conto nell’analisi. Possiamo farlo in diversi modi: \n\n- includendo la variabile di confondimento in una regressione,  \n- selezionando gruppi di confronto simili (matching),  \n- oppure, idealmente, usando la randomizzazione sperimentale, che rende i gruppi equivalenti su fattori non osservati.\n\nIn sintesi: senza controllare per la motivazione, i dati ci ingannano; includendo la motivazione, possiamo distinguere tra *correlazione spuria* e *relazione causale reale*.\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nStudiare la causalità non è solo un esercizio teorico. Ogni volta che uno psicologo legge un articolo, progetta un esperimento o valuta un trattamento, deve chiedersi: ‘Questa relazione che osservo è davvero causale o è il frutto di un confondimento?’ Imparare a distinguere questi casi significa fare scienza psicologica più solida e utile.\n\nIn questo capitolo abbiamo visto che studiare la causalità in psicologia è complesso, ma non impossibile.  Abbiamo distinto tra *correlazione* e *causalità*, imparato a rappresentare le nostre ipotesi con i *grafi causali*, e discusso il ruolo di concetti come *confondimento*, *mediazione* e *moderazione*.  \n\nAbbiamo poi esaminato i principali strumenti per testare le ipotesi causali:  \n\n- *esperimenti controllati*, il metodo più solido,  \n- *quasi-esperimenti*, utili quando non possiamo randomizzare,  \n- *studi osservativi*, che richiedono l’uso di tecniche statistiche per ridurre i rischi di interpretazioni errate.\n\nLa lezione principale è che i dati, da soli, non “parlano”: hanno bisogno di un *modello teorico* che guidi l’interpretazione.  Un’analisi statistica, per quanto sofisticata, non può dirci nulla di causale se non abbiamo prima formulato ipotesi chiare sul meccanismo che vogliamo studiare.  \n\n\n::: {.callout-tip collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#> [8] base     \n#> \n#> other attached packages:\n#>  [1] ggdag_0.2.13          pillar_1.11.0         tinytable_0.13.0     \n#>  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#>  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [25] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#> [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#> [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#> [16] labeling_0.4.3        ggraph_2.2.2          rmarkdown_2.29       \n#> [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#> [22] cachem_1.1.0          jsonlite_2.0.0        tweenr_2.0.3         \n#> [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#> [28] stringi_1.8.7         RColorBrewer_1.1-3    boot_1.3-32          \n#> [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#> [34] zoo_1.8-14            Matrix_1.7-4          splines_4.5.1        \n#> [37] igraph_2.1.4          timechange_0.3.0      tidyselect_1.2.1     \n#> [40] viridis_0.6.5         abind_1.4-8           yaml_2.3.10          \n#> [43] codetools_0.2-20      curl_7.0.0            dagitty_0.3-4        \n#> [46] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#> [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#> [52] survival_3.8-3        polyclip_1.10-7       RcppParallel_5.1.11-1\n#> [55] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#> [58] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#> [61] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#> [64] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#> [67] graphlayouts_1.2.2    mvtnorm_1.3-3         tidygraph_1.3.1      \n#> [70] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#> [73] ggforce_0.5.0         cli_3.6.5             textshaping_1.0.3    \n#> [76] svUnit_1.0.8          viridisLite_0.4.2     Brobdingnag_1.2-9    \n#> [79] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#> [82] ggrepel_0.9.6         TH.data_1.1-4         htmlwidgets_1.6.4    \n#> [85] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#> [88] lifecycle_1.0.4       MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n",
    "supporting": [
      "09_causality_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}