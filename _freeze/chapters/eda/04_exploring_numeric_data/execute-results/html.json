{
  "hash": "719705af9022f07751e298fa072e830a",
  "result": {
    "engine": "knitr",
    "markdown": "# Esplorare i dati numerici {#sec-eda-exploring-num-data}\n\n::: {.epigraph}\n> “Exploratory data analysis can never be the whole story, but nothing else can serve as the foundation stone.”\n>\n> -- **John W. Tukey**, Exploratory Data Analysis (1977)\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nIn questo capitolo ci concentreremo sull'analisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione più comuni, come l'istogramma, l'istogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- costruire e interpretare distribuzioni di frequenza e cumulative;  \n- comprendere e confrontare istogrammi e stime di densità kernel;  \n- utilizzare boxplot e violin plot per individuare differenze tra gruppi;  \n- riconoscere la forma di una distribuzione e i suoi indici di posizione;  \n- comunicare i risultati con grafici chiari ed efficaci. \n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere l'Appendice @sec-apx-sums prima di procedere con la lettura di questo capitolo.\n- Leggere il capitolo [Exploring numerical data](https://openintro-ims.netlify.app/explore-numerical) di [Introduction to Modern Statistics (2e)](https://openintro-ims.netlify.app) di Mine Çetinkaya-Rundel e Johanna Hardin.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(ggbeeswarm, dslabs, gridExtra, ggpubr, cowplot, viridis)\n```\n:::\n\n:::\n\n\n## Le aspettative negative nella depressione\n\nConsideriamo i dati relativi alle aspettative negative, individuate come un meccanismo chiave nel mantenimento della depressione [@zetsche_2019future]. Supponiamo di voler analizzare la distribuzione di una singola variabile quantitativa.\n\nImportiamo i dati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- rio::import(here::here(\"data\", \"data.mood.csv\"))\n```\n:::\n\n\n\n### Data Wrangling\n\nPer questo esercizio, ci concentreremo sulle variabili `esm_id` (il codice del soggetto), `group` (il gruppo) e `bdi` (il valore BDI-II).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- df |> \n  dplyr::select(\"esm_id\", \"group\", \"bdi\")\ndf |> \n  head()\n#>   esm_id group bdi\n#> 1     10   mdd  25\n#> 2     10   mdd  25\n#> 3     10   mdd  25\n#> 4     10   mdd  25\n#> 5     10   mdd  25\n#> 6     10   mdd  25\n```\n:::\n\n\nSe elenchiamo le modalità presenti in `group` utilizzando il metodo `unique()`, scopriamo che corrispondono a `mdd` (pazienti) e `ctl` (controlli sani).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf$group |> \n  unique()\n#> [1] \"mdd\" \"ctl\"\n```\n:::\n\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- df[!duplicated(df), ]\n```\n:::\n\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndim(df)\n#> [1] 67  3\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(df)\n#>    esm_id group bdi\n#> 1      10   mdd  25\n#> 15      9   mdd  30\n#> 30      6   mdd  26\n#> 46      7   mdd  35\n#> 65     12   mdd  44\n#> 83     16   mdd  30\n```\n:::\n\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il \"nome\" delle righe (ovvero, l'indice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga è 15. Questo non ha nessuna conseguenza perché non useremo l'indice di riga nelle analisi seguenti.\n\nEliminiamo eventuali valori mancanti:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- df[!is.na(df$bdi), ]\n```\n:::\n\n\nOtteniamo così il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndim(df)\n#> [1] 66  3\n```\n:::\n\n\n\n### Anteprima dei dati  \n\nPrima di approfondire l'analisi, è fondamentale esaminare una anteprima dei dati per comprenderne struttura, formati e potenziali anomalie.  \n\nLa funzione `glimpse()` fornisce una panoramica compatta del dataset: numero di righe/colonne, tipo di variabili (es. `chr`, `num`, `dbl`) ed esempi di valori. Utile per identificare rapidamente formati errati o colonne non attese:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(df)  \n#> Rows: 66\n#> Columns: 3\n#> $ esm_id <int> 10, 9, 6, 7, 12, 16, 21, 18, 20, 22, 23, 25, 24, 26, 41, 31, 27…\n#> $ group  <chr> \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", …\n#> $ bdi    <int> 25, 30, 26, 35, 44, 30, 22, 33, 43, 43, 24, 39, 19, 3, 0, 25, 0…\n```\n:::\n\n\nLa funzione `summary()` genera statistiche descrittive per ogni colonna:  \n\n- per variabili numeriche: media, mediana, quartili, min/max; \n- per variabili categoriche: frequenza dei livelli; \n- segnala valori mancanti (`NA`), aiutando a valutare la qualità dei dati.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(df)  \n#>      esm_id         group                bdi       \n#>  Min.   :  6.0   Length:66          Min.   : 0.00  \n#>  1st Qu.: 30.2   Class :character   1st Qu.: 0.25  \n#>  Median : 46.5   Mode  :character   Median : 6.00  \n#>  Mean   : 51.6                      Mean   :14.94  \n#>  3rd Qu.: 76.8                      3rd Qu.:29.50  \n#>  Max.   :104.0                      Max.   :44.00\n```\n:::\n\n\nI comandi `head()` e `tail()` ci permettono di visualizzare le prime o le ultime righe di un dataset:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(df)\n#>    esm_id group bdi\n#> 1      10   mdd  25\n#> 15      9   mdd  30\n#> 30      6   mdd  26\n#> 46      7   mdd  35\n#> 65     12   mdd  44\n#> 83     16   mdd  30\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntail(df)\n#>      esm_id group bdi\n#> 1087    101   ctl   9\n#> 1105     99   ctl   0\n#> 1121    100   ctl   2\n#> 1133    104   ctl   0\n#> 1152    103   ctl   0\n#> 1171    102   ctl   1\n```\n:::\n\n\n\n### Conversione da `char` a `factor`\n\nIn R, i tipi di dato *character* e *factor* rappresentano informazioni testuali, ma hanno utilizzi distinti:\n\n- *character*: è una semplice stringa di testo;\n- *factor*: è una variabile categoriale, ideale per rappresentare dati con un numero finito di categorie (livelli). I dati in formato `factor` sono utili per analisi statistiche, poiché trattano i valori come categorie discrete.\n\nNel seguente esempio, convertiamo una variabile `group` da `character` a `factor`, in modo da poterla utilizzare come variabile categoriale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf$group <- as.factor(df$group)  # Converte 'group' in un factor\n```\n:::\n\n\nSuccessivamente, il comando `summary()` fornisce un riepilogo della variabile categoriale, mostrando il conteggio dei valori per ciascun livello:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(df$group)\n#> ctl mdd \n#>  36  30\n```\n:::\n\n\n## Distribuzioni di frequenza\n\nLe distribuzioni di frequenza sono strumenti essenziali per visualizzare e comprendere la variabilità di una variabile. In questo capitolo verrà illustrato come costruire una distribuzione di frequenza e, successivamente, come generare in R una distribuzione cumulativa empirica, un istogramma, un Kernel Density Plot e un boxplot.\n\nA titolo esemplificativo, consideriamo i punteggi del BDI-II. Iniziamo ordinando i dati in ordine crescente:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf$bdi |> sort()\n#>  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1\n#> [26]  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28 28 30\n#> [51] 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44\n```\n:::\n\n\nUna distribuzione di frequenza evidenzia quante volte i valori di una variabile ricorrono in determinati intervalli. Ad esempio, per i punteggi del BDI-II è consuetudine raggruppare i dati nelle seguenti classi:\n\n- 0–13: depressione minima;\n- 14–19: depressione lieve-moderata;\n- 20–28: depressione moderata-severa;\n- 29–63: depressione severa.\n\nDefinendo ciascuna classe, indicata con $\\Delta_i$, come un intervallo $[a_i, b_i)$ o $(a_i, b_i]$, possiamo calcolare le seguenti misure:\n\n- *Frequenza assoluta ($n_i$)*: numero di osservazioni in $\\Delta_i$. La somma delle frequenze assolute corrisponde al totale delle osservazioni, $n$.\n- *Frequenza relativa ($f_i$)*: proporzione di osservazioni in $\\Delta_i$, calcolata come $f_i = n_i/n$; la somma delle frequenze relative è pari a 1.\n- *Frequenza cumulata ($N_i$)*: somma delle frequenze assolute fino alla classe $i$, ovvero $N_i = \\sum_{j=1}^i n_j$.\n- *Frequenza cumulata relativa ($F_i$)*: somma delle frequenze relative fino alla classe $i$, data da $F_i = \\sum_{j=1}^i f_j$.\n\nQueste misure consentono di sintetizzare la distribuzione dei punteggi, facilitando l’interpretazione delle caratteristiche del campione.\n\n\n### Frequenze assolute e relative\n\nPer analizzare la distribuzione dei punteggi BDI-II nel dataset di @zetsche_2019future, è utile creare una variabile categoriale che classifichi ogni osservazione in una delle quattro classi di gravità della depressione. A tal fine, utilizziamo la funzione `cut()`, che permette di suddividere il vettore dei punteggi (`bdi`) in intervalli definiti.\n\nNel comando seguente, il parametro `breaks` specifica i limiti degli intervalli, mentre `include.lowest = TRUE` garantisce che il valore minimo sia incluso nel primo intervallo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Creazione della variabile categoriale per i livelli di depressione\ndf <- df %>% \n  mutate(\n    bdi_class = cut(\n      bdi, \n      breaks = c(0, 13.5, 19.5, 28.5, 63),\n      include.lowest = TRUE\n    )\n  )\n```\n:::\n\n\nI punteggi vengono suddivisi nelle seguenti classi:\n\n- 0–13: depressione minima;\n- 14–19: depressione lieve-moderata;\n- 20–28: depressione moderata-;\n- 29–63: depressione severa.\n\nUna volta creata la variabile `bdi_class`, possiamo calcolare le frequenze assolute e relative.\n\n\n#### Frequenze assolute\n\nUtilizzando la funzione `table()`, si ottiene il numero di osservazioni in ciascuna classe:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(df$bdi_class)\n#> \n#>    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#>          36           1          12          17\n```\n:::\n\n\n\n#### Frequenze relative\n\nCon `prop.table()` è possibile determinare la proporzione di osservazioni per ogni classe:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprop.table(table(df$bdi_class))\n#> \n#>    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#>      0.5455      0.0152      0.1818      0.2576\n```\n:::\n\n\n\n### Distribuzioni congiunte\n\nLe distribuzioni congiunte di frequenze permettono di analizzare la relazione tra due variabili, considerando tutte le possibili combinazioni dei loro valori. Ad esempio, se analizziamo le variabili `bdi_class` e `group`, la tabella congiunta mostrerà la frequenza (assoluta o relativa) per ogni coppia di valori.\n\nPer ottenere la distribuzione congiunta relativa, utilizziamo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprop.table(table(df$bdi_class, df$group))\n#>              \n#>                  ctl    mdd\n#>   [0,13.5]    0.5455 0.0000\n#>   (13.5,19.5] 0.0000 0.0152\n#>   (19.5,28.5] 0.0000 0.1818\n#>   (28.5,63]   0.0000 0.2576\n```\n:::\n\n\nIn questo modo, possiamo esaminare come le classi di punteggi BDI-II si distribuiscono all’interno dei diversi gruppi, con la somma complessiva delle frequenze relative pari a 1.\n\n\n### La distribuzione cumulativa empirica\n\nLa *distribuzione cumulativa empirica* (eCDF, *empirical Cumulative Distribution Function*) è un modo utile per rappresentare la distribuzione di dati numerici. Questa funzione indica la proporzione di dati che sono inferiori o uguali a un certo valore $a$, per tutti i possibili valori di $a$. Matematicamente, la eCDF è definita come:\n\n$$\nF(a) = \\text{Proporzione dei dati con valore} \\leq a.\n$$\n\nIn altre parole, la eCDF ci dice quale frazione dei dati osservati è minore o uguale a un determinato valore $a$. Questo è particolarmente utile per comprendere come i dati sono distribuiti e per identificare pattern o caratteristiche specifiche della distribuzione, come la presenza di bimodalità (cioè, due picchi distinti nella distribuzione).\n\n\n#### Esempio con i dati di @zetsche_2019future\n\nNel contesto dei dati di @zetsche_2019future, possiamo utilizzare la eCDF per visualizzare la distribuzione dei punteggi BDI-II. Ecco come viene rappresentata la eCDF per l'intero dataset:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf |> \n  ggplot(aes(bdi)) + \n  stat_ecdf() +\n  labs(x = \"BDI\", y = \"F(BDI)\")\n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIn questo grafico:\n\n- l'asse $x$ rappresenta i valori del BDI-II,\n- l'asse $y$ rappresenta la proporzione cumulativa dei dati, cioè $F(a)$.\n\n\n#### Interpretazione del grafico\n\n1. *Crescita della curva*: La curva della eCDF parte da 0 (nessun dato è inferiore al valore minimo osservato) e cresce gradualmente fino a 1 (tutti i dati sono inferiori o uguali al valore massimo osservato).\n2. *Bimodalità*: Se la curva presenta dei \"gradini\" o delle aree con una pendenza più ripida, questo può indicare la presenza di bimodalità, ovvero due gruppi distinti di dati con caratteristiche diverse. Nel caso dei dati BDI-II, la bimodalità potrebbe riflettere la presenza di due sottogruppi di partecipanti con livelli di depressione diversi.\n\n\n#### Filtrare i dati per il campione clinico\n\nSe vogliamo analizzare solo i dati relativi al campione clinico (ad esempio, i pazienti con depressione maggiore), possiamo filtrare i dati e rappresentare la eCDF solo per questo gruppo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf |> dplyr::filter(group == \"mdd\") |> \n  ggplot(aes(bdi)) + \n  stat_ecdf() +\n  labs(x = \"a\", y = \"F(a)\")\n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIn questo caso, la eCDF ci mostrerà come i punteggi BDI-II sono distribuiti tra i pazienti con depressione maggiore, permettendoci di identificare eventuali pattern specifici per questo gruppo.\n\nIn sintesi, la eCDF è uno strumento potente per analizzare e visualizzare la distribuzione di dati numerici, specialmente quando si vogliono identificare pattern specifici o confrontare distribuzioni tra diversi gruppi.\n\n\n## Istogramma\n\nSebbene il concetto di *Funzione di Distribuzione Empirica Cumulativa* (eCDF) venga ampiamente discusso nei testi di statistica, in pratica tale rappresentazione non è molto diffusa. Il motivo principale è che l'eCDF non rende immediatamente visibili alcune caratteristiche fondamentali della distribuzione, come il valore intorno al quale essa è centrata, se la distribuzione sia simmetrica o quali intervalli contengano il 95% dei dati, ad esempio. Gli istogrammi, invece, sono molto più utilizzati perché facilitano notevolmente la comprensione di queste proprietà, sacrificando solo un po' di informazione per fornire una rappresentazione più intuitiva.\n\nUn *istogramma* è un grafico che rappresenta la distribuzione delle frequenze di una variabile. Sull’asse orizzontale (ascisse) vengono indicati i limiti delle classi $\\Delta_i$, mentre sull’asse verticale (ordinate) si riporta la densità della frequenza relativa della variabile $X$ per ciascuna classe $\\Delta_i$.\n\nPer descrivere formalmente la densità della frequenza relativa, si utilizza una funzione costante a tratti definita come:\n\n$$\n\\varphi_n(x) = \\frac{f_i}{b_i - a_i},\n$$\n\ndove:\n\n- $f_i$ è la frequenza relativa della classe $\\Delta_i$,\n- $b_i - a_i$ è l’ampiezza della classe $\\Delta_i$.\n\nIn questo modo, l’area del rettangolo corrispondente a $\\Delta_i$ in un istogramma risulta proporzionale alla frequenza relativa $f_i$. Poiché la somma delle frequenze relative deve essere pari a 1, l’area totale di un istogramma delle frequenze relative risulta anch’essa uguale a 1, corrispondendo alla somma delle aree di tutti i rettangoli.\n\nGli istogrammi costituiscono quindi uno strumento essenziale per visualizzare e comprendere le principali caratteristiche di una distribuzione, agevolando l’analisi della sua forma, della sua tendenza centrale e della sua dispersione.\n\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di @zetsche_2019future. Con i quattro intervalli individuati dai cut-off del BDI-II creiamo una prima versione dell'istogramma -- si notino le frequenze assolute sull'asse delle ordinate.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    breaks = c(0, 13.5, 19.5, 28.5, 63),\n    aes(y = after_stat(density)),  # oppure after_stat(count / sum(count))\n    linewidth = 0.5\n  ) +\n  labs(\n    x = \"BDI-II\", \n    y = \"Densità\"\n  ) \n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nAnche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un'ampiezza uguale. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    aes(y = after_stat(density))\n  ) +\n  labs(\n    x = \"BDI-II\", \n    y = \"Densità\"\n  )\n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n## Kernel Density Plot\n\nUn limite evidente degli istogrammi è che la loro forma dipende da scelte arbitrarie: il numero e l’ampiezza delle classi (o *bin*) può infatti influenzare in modo sostanziale l’aspetto finale del grafico, rendendo più difficile l’interpretazione della distribuzione dei dati. Una soluzione a questo problema è offerta dalla *stima della densità kernel* (*Kernel Density Estimation*, KDE), un metodo che fornisce un profilo continuo e smussato della distribuzione, meno condizionato dall’arbitrarietà delle classi.\n\n\n### Differenza tra istogramma e KDE\n\nNell’istogramma, dividiamo l’asse orizzontale in intervalli di ampiezza prefissata (i *bin*) e costruiamo rettangoli la cui altezza è proporzionale alla frequenza (o densità) dei dati che ricadono in ciascun intervallo. Se cambiamo il numero o la larghezza dei bin, la forma dell’istogramma può variare sensibilmente.\n\nLa KDE, invece, non suddivide i dati in intervalli fissi. Al contrario, “appoggia” una piccola curva (il *kernel*) su ogni singola osservazione. Le curve utilizzate (ad esempio di tipo gaussiano) hanno una larghezza, detta *bandwidth*, che controlla il grado di *smussamento*: con un bandwidth molto piccolo, la stima segue da vicino le singole osservazioni, generando un profilo più frastagliato; con un bandwidth più ampio, la curva risultante è più liscia, ma rischia di nascondere dettagli importanti.\n\nPer comprendere in modo intuitivo il concetto di KDE, possiamo partire da un esempio semplice. Immaginiamo di costruire un istogramma con classi di ampiezza sempre più piccola. Se avessimo a disposizione un numero *enorme* di dati (ad esempio, un milione di misurazioni dell'altezza di individui) e li rappresentassimo con bin sempre più stretti (0.1, 0.01, ecc.), l'istogramma diventerebbe sempre più levigato, avvicinandosi a una curva continua. Questo processo illustra l'idea alla base della KDE, che approssima la distribuzione dei dati in modo fluido e continuo.\n\nLa KDE, tuttavia, opera in modo più elegante e senza richiedere un numero enorme di punti: posiziona un piccolo “dosso di campana” (o un altro tipo di kernel) su ciascun punto dati e somma tutte queste curve in un’unica curva finale.\n\n::: {.callout-note}\n## Che cosa vuol dire “dosso di campana”?\n\nPossiamo immaginarlo come una piccola curva gaussiana: una curva simile alla forma di una campana che si innalza e poi discende dolcemente.\n\n- Ogni singolo dato viene “coperto” da questa mini-campana.\n- L’ampiezza (o “larghezza”) della campana è regolata dal bandwidth, che stabilisce se la curva sarà più o meno “distesa” sul grafico.\n- Sommando tutte le piccole campane (una per ogni osservazione), otteniamo una curva di densità liscia e continua che rappresenta la distribuzione dei dati senza i “salti” tipici dell’istogramma.\n:::\n\nIl risultato è una *curva di densità* che:\n\n1. *È continua*: a differenza degli istogrammi, non presenta bruschi salti di altezza tra i bin: la curva scorre in modo uniforme lungo tutto l’asse orizzontale.\n2. *Mostra la proporzione di dati in ogni intervallo*: l'area sotto la curva in un determinato range corrisponde alla percentuale (o probabilità) di dati che cadono in quell'intervallo.\n3. *Dipende dal bandwidth*: \n    - Un bandwidth *piccolo* produce una curva più ondulata e “frastagliata” (poiché segue da vicino ogni singolo dato).\n    - Un bandwidth *grande* genera una curva più liscia e arrotondata, ma rischia di “coprire” troppi dettagli della distribuzione originaria.\n\nSi noti che la stima della densità kernel introduce, tuttavia, un’ipotesi di fondo: che la distribuzione dei dati “reali” sia “liscia” e non presenti discontinuità improvvise. Questo è spesso ragionevole (ad esempio per dati fisiologici come l’altezza), ma in altri casi potrebbe non esserlo. È quindi importante scegliere un bandwidth che rifletta adeguatamente il livello di dettaglio che vogliamo mostrare.\n\nInoltre, l’asse delle ordinate (l’asse *y*) rappresenta la densità, non la frequenza assoluta. È possibile costruire un istogramma in cui l’altezza dei rettangoli mostra quante osservazioni ricadono in ciascun bin. Nella KDE, l’altezza della curva è tale che l’area totale sotto di essa sia pari a 1, rispecchiando la natura di una funzione di densità di probabilità.\n\nDi seguito esaminiamo un esempio che mostra la costruzione passo dopo passo di istogrammi con diversi valori di binwidth, fino a passare a una stima di densità. Consideriemo un dataset con un numero di osservazioni molto elevato (i valori di altezza, `heights`, riportati da 1050 partecipanti, estratti dal pacchetto `dslabs`), suddiviso in due gruppi: maschi e femmine. Ecco come potremmo prima costruire un istogramma di altezze per i maschi, per poi tracciare una curva di densità smussata:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Istogramma con bin di ampiezza 1\nggplot(heights |> dplyr::filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(\n    binwidth = 1\n  )\n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-25-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Aggiunta della curva di densità sopra l'istogramma\nggplot(heights |> dplyr::filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    binwidth = 1\n  ) +\n  geom_line(stat = 'density')\n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-26-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nVariando il parametro di regolazione (*adjust* o *bandwidth*) nella funzione `geom_density()`, possiamo modificare il livello di smussamento:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Istogramma base con alpha e colore coerente\np <- ggplot(heights |> filter(sex == \"Male\"), aes(x = height)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    binwidth = 1\n  ) +\n  labs(\n    x = \"Altezza\",\n    y = \"Densità\"\n  )\n\n# Più ondulato (banda piccola)\np1 <- p +\n  geom_line(stat = \"density\", adjust = 0.5) +\n  labs(subtitle = \"Smoothing accentuato (adjust = 0.5)\")\n\n# Più liscio (banda larga)\np2 <- p +\n  geom_line(stat = \"density\", adjust = 2) +\n  labs(subtitle = \"Smoothing attenuato (adjust = 2)\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np1\n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-28-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np2\n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nPer illustrare ulteriormente l’uso della KDE, ora consideriamo i punteggi BDI-II di  @zetsche_2019future. Con il codice seguente creiamo due curve di densità, una per ogni gruppo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = bdi, fill = group)) +\n  geom_density() +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densità\"\n  )\n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-30-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nQui, la sovrapposizione delle due curve ci consente di confrontare la distribuzione dei punteggi BDI-II tra i due gruppi in maniera molto più *fluida* e intuitiva rispetto a quanto faremmo con due istogrammi separati o con un istogramma combinato. Inoltre, non siamo più vincolati alla scelta dei bin: l’aspetto delle curve dipende soltanto dalla funzione kernel utilizzata e dal parametro di smussamento. \n\nIn conclusione, \n\n- l’*istogramma* rimane uno strumento rapido e intuitivo, *privo di assunzioni*, ma sensibile alla scelta di numero e ampiezza dei bin;\n- la *stima della densità kernel (KDE)* offre una rappresentazione continua della distribuzione dei dati, fornendo un quadro più “morbido” e spesso più informativo. Tuttavia, introduce alcune assunzioni e richiede la scelta del bandwidth ottimale.\n\nIn definitiva, è consigliabile usare entrambe le tecniche per ottenere una panoramica completa dei propri dati: l’istogramma permette di dare un primo sguardo alla loro distribuzione “grezza” (senza presupposti), mentre la KDE aiuta a comprenderne l’eventuale struttura “liscia” di fondo.\n\n\n### Area sottesa alla curva di densità: un'interpretazione probabilistica\n\nQuando si lavora con una curva di densità, è importante capire che l'area totale sotto la curva rappresenta la probabilità totale, che è sempre pari a 1 (o 100%). Questo significa che l'area sotto la curva in un determinato intervallo corrisponde alla probabilità che un dato valore cada in quell'intervallo.\n\n\n#### Come interpretare l'asse Y\n\nL'asse y di un grafico di densità non rappresenta direttamente la probabilità, ma è scalato in modo che l'area totale sotto la curva sia uguale a 1. Se immaginiamo di creare un \"bin\" (un intervallo) con una base di 1 unità di lunghezza, il valore sull'asse y ci indica la proporzione di valori che cadono in quel bin. Tuttavia, questa interpretazione è valida solo per bin di dimensione 1. Per intervalli di altre dimensioni, il modo migliore per determinare la proporzione di dati in quell'intervallo è calcolare la proporzione dell'area totale sotto la curva che cade in quell'intervallo.\n\n\n#### Esempio pratico\n\nConsideriamo un esempio con i dati delle altezze degli uomini. Supponiamo di voler sapere quale proporzione di uomini ha un'altezza compresa tra 65 e 68 pollici. Per farlo, calcoliamo l'area sotto la curva di densità in quell'intervallo.\n\nEcco come appare graficamente:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/summaries-area-under-curve-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nL'area evidenziata in azzurro rappresenta la proporzione di uomini con altezza tra 65 e 68 pollici. Calcolando questa area, troviamo che circa il 0.3 (ovvero il 30% degli uomini ha un'altezza in questo intervallo.\n\n\n#### Utilizzo della curva di densità come riepilogo\n\nComprendendo questo concetto, possiamo utilizzare la curva di densità come un efficace strumento di riepilogo. Per questo dataset, l'assunzione di smoothness (lisciatura) della curva è ragionevole, e possiamo condividere questa rappresentazione grafica per comunicare in modo chiaro e intuitivo la distribuzione delle altezze degli uomini.\n\nEcco un esempio di come appare la curva di densità smooth per le altezze degli uomini:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/summaries-example-of-smoothed-density-2-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIn sintesi, l'area sotto la curva di densità in un determinato intervallo rappresenta la probabilità che un valore casuale cada in quell'intervallo, rendendo la curva di densità uno strumento potente per comprendere e comunicare la distribuzione dei dati.\n\n\n## Forma di una distribuzione\n\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un'illustrazione grafica è fornita nella figura seguente. Nel pannello 1, la distribuzione è unimodale con asimmetria negativa; nel pannello 2, la distribuzione è unimodale con asimmetria positiva; nel pannello 3, la distribuzione è simmetrica e unimodale; nel pannello 4, la distribuzione è bimodale.\n\n![Distribuzioni](../../figures/shape_distribution.png){width=\"55%\"}\n\nIl grafico della densità di kernel (Kernel Density Plot) dei valori BDI-II nel campione di @zetsche_2019future è bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l'altro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da @zetsche_2019future.\n\n\n## Indici di posizione\n\n### Quantili\n\nLa distribuzione dei valori BDI-II di @zetsche_2019future può essere sintetizzata attraverso l'uso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, $q_1$, divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, $q_2$, corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\n\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\n\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di $np$, dove $n$ è la dimensione del campione e $p$ è l'ordine del quantile. Se $np$ non è un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di $np$. Se $np$ è un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni $k$ e $k+1$, dove $k$ è la parte intera di $np$.\n\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che è molto popolare e può essere utilizzata in alternativa ad un istogramma.\n\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di @zetsche_2019future, si determina il valore di $np = 9 \\cdot 0.5 = 4.5$, che non è un intero. Pertanto, il valore del secondo quartile è pari al valore del dato che si trova alla posizione successiva alla parte intera di $np$, ovvero $q_2 = x_{4 + 1} = 27$. Per calcolare il quantile di ordine $2/3$, si determina il valore di $np = 9 \\cdot 2/3 = 6$, che è un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni $6$ e $7$, ovvero $q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33$.\n\nUsiamo `quantile()` per trovare la soluzione dell'esercizio precedente.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx = c(19, 26, 27, 28, 28, 33, 33, 41, 43)\nquantile(x, 2 / 3)\n#> 66.66667% \n#>        33\n```\n:::\n\n\n\n## Mostrare i dati\n\n### Diagramma a scatola\n\nIl box plot è uno strumento grafico che visualizza la dispersione di una distribuzione. I *boxplot* forniscono una rappresentazione visiva sintetica di cinque valori caratteristici: *minimo*, *primo quartile (25%)*, *mediana (50%)*, *terzo quartile (75%)* e *massimo*. Spesso però, i boxplot “ignorano” i valori considerati anomali (*outlier*), segnalandoli con punti isolati. \n\nPer creare un box plot, si disegna un rettangolo (la \"scatola\") di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile ($q_{0.75}$) e il primo quartile ($q_{0.25}$). La mediana ($q_{0.5}$) è rappresentata da una linea all'interno del rettangolo.\n\nAi lati della scatola, vengono tracciati due segmenti di retta, detti \"baffi\", che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore è il valore più basso tra le osservazioni che è maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più alto tra le osservazioni che è minore o uguale al terzo quartile più 1.5 volte la distanza interquartile.\n\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati \"valori anomali\" e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\n![](../../figures/boxplot.png){width=\"90%\"}\n\n### Stratificazione\n\nNell'analisi dei dati, è comune suddividere le osservazioni in gruppi in base ai valori di una o più variabili associate a tali osservazioni. Questo processo è chiamato *stratificazione*, e i gruppi risultanti sono detti *strati*. Ad esempio, nella sezione successiva, dividiamo i valori dei punteggi BDI-II in due gruppi in base alla condizione sperimentale: campione clinico e campione di controllo. \n\nLa stratificazione è particolarmente utile nella visualizzazione dei dati, poiché spesso siamo interessati a comprendere come la distribuzione di una variabile differisca tra diversi sottogruppi. \n\nPer esempio, per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo, possiamo utilizzare un box-plot. Questo tipo di grafico ci permette di confrontare visivamente la distribuzione dei punteggi tra i due gruppi, evidenziando eventuali differenze.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = group, y = bdi)) +\n  geom_boxplot() +\n  labs(\n    x = \"Gruppo\", \n    y = \"BDI-II\"\n  )\n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-32-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIn questo grafico:\n\n- l'asse *x* rappresenta i due gruppi (pazienti e controllo),\n- l'asse *y* rappresenta i punteggi BDI-II,\n- i box (scatole) mostrano la distribuzione dei punteggi, con la linea centrale che indica la mediana e i \"baffi\" che rappresentano la variabilità dei dati.\n\nLa stratificazione ci aiuta a identificare rapidamente se ci sono differenze nella distribuzione dei punteggi BDI-II tra i due gruppi. Nel caso presente, il grafico mostra come non vi sia alcuna sovrapposizione tra le due distribuzioni.\n\nUn risultato migliore si ottiene utilizzando un grafico a violino (*violin plot*) e includendo anche i dati grezzi.\n\n\n### Grafico a violino\n\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densità di kernel (KDE plot) per offrire una rappresentazione più dettagliata dei dati. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = group, y = bdi, fill = group)) +\n  geom_violin() +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )\n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-33-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n### Grafico Beeswarm\n\nIl pacchetto *{ggbeeswarm}* include una funzione chiamata `geom_beeswarm`, che può essere utilizzata per creare un grafico beeswarm in ggplot2. Un grafico beeswarm è una variazione del grafico a punti che disperde i dati in modo che non si sovrappongano, rendendo visibili tutti i singoli punti dati. Questo tipo di visualizzazione è particolarmente utile quando si desidera esaminare la distribuzione e la densità di un set di dati, senza ricorrere all'uso di barre d'errore o di scatole e baffi (boxplot), mantenendo un'alta leggibilità anche quando i set di dati sono densi.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = group, y = bdi, color = group)) +\n  geom_beeswarm(cex = 2) +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  ) \n```\n\n::: {.cell-output-display}\n![](04_exploring_numeric_data_files/figure-html/unnamed-chunk-34-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo illustrato una varietà di tecniche per sintetizzare e visualizzare i dati numerici, concentrandoci sia sugli aspetti descrittivi (come distribuzioni di frequenze, istogrammi e distribuzioni cumulative) sia su metodi più raffinati come la stima della densità kernel. Questi strumenti non solo facilitano la comprensione immediata dei pattern e delle caratteristiche fondamentali dei dati, ma rappresentano anche un passaggio essenziale per identificare anomalie e guidare ulteriori analisi statistiche.\n\nLa capacità di trasformare dati grezzi in rappresentazioni grafiche chiare e intuitive è fondamentale per comunicare in modo efficace i risultati dell’analisi, soprattutto quando si tratta di supportare decisioni pratiche o di sviluppare ipotesi di ricerca. In questo senso, una visualizzazione accurata e ben strutturata consente di evidenziare aspetti come la forma della distribuzione, la presenza di outlier e le differenze tra sottogruppi, contribuendo a una più profonda interpretazione dei fenomeni studiati.\n\nInfine, l’integrazione di tecniche di visualizzazione con analisi statistiche sintetiche migliora la trasparenza e l’interpretabilità dei dati, offrendo un quadro completo che supporta sia la valutazione critica che la comunicazione dei risultati.\n\n\n::: {.callout-important title=\"Problemi\" collapse=\"true\"}\nIn questo esercizio, gli studenti raccoglieranno e analizzeranno dati relativi alla **Satisfaction With Life Scale (SWLS)** [@Diener1985] e alla **Scala della Rete Sociale di Lubben (LSNS-6)** [@Lubben2006]. L'obiettivo è comprendere la relazione tra la soddisfazione di vita e la qualità delle relazioni sociali, esplorando la distribuzione delle variabili e le possibili associazioni tra di esse.\n\nLa **Scala della Rete Sociale di Lubben a 6 item (LSNS-6)** è uno strumento utilizzato per valutare l'isolamento sociale negli adulti più anziani, misurando il supporto sociale percepito sia da parte dei familiari che degli amici. La scala comprende sei domande suddivise in due sezioni:\n\n**FAMIGLIA: Considerando le persone a cui sei legato per nascita, matrimonio, adozione, ecc.**\n\n1. Quanti parenti vedi o senti almeno una volta al mese?\n2. Con quanti parenti ti senti a tuo agio nel parlare di questioni personali?\n3. Con quanti parenti ti senti così vicino da poter chiedere loro aiuto?\n\n**AMICIZIE: Considerando tutti i tuoi amici, inclusi quelli che vivono nel tuo quartiere**\n\n4. Quanti dei tuoi amici vedi o senti almeno una volta al mese?\n5. Con quanti amici ti senti a tuo agio nel parlare di questioni personali?\n6. Con quanti amici ti senti così vicino da poter chiedere loro aiuto?\n\nLa scala di risposta è:\n\n   - 0 = nessuno\n   - 1 = uno\n   - 2 = due\n   - 3 = tre o quattro\n   - 4 = da cinque a otto\n   - 5 = nove o più\n\nIl punteggio totale della LSNS-6 si ottiene sommando i punteggi dei sei item, con un range che va da 0 a 30. Un punteggio di 12 o inferiore indica un rischio di isolamento sociale. \n\n**Dati da Raccogliere** \n\nOgni studente dovrà raccogliere i seguenti dati su se stesso e sui membri del proprio gruppo TPV:\n\n- **`student_id`**: Identificativo univoco dello studente.  \n- **`group`**: Gruppo di appartenenza (es. Gruppo 1, Gruppo 2, ecc.).  \n- **`swls`**: Punteggio totale sulla Satisfaction With Life Scale (SWLS).  \n- **`gender`**: Genere (`M`, `F`).  \n- **`lsns_total`**: Punteggio totale della Scala della Rete Sociale di Lubben (LSNS-6).  \n- **`lsns_family`**: Punteggio della sottoscala *engagement with family members* (somma degli item 1-3).  \n- **`lsns_friends`**: Punteggio della sottoscala *engagement with friends* (somma degli item 4-6).  \n\nQueste variabili permetteranno di investigare come la **soddisfazione di vita** sia associata alla **quantità e qualità delle relazioni sociali**, distinguendo tra contatti con la famiglia e con gli amici.\n\n**Obiettivi dell'Analisi**  \n\nL'esercizio è strutturato in tre parti:\n\n1. **Esplorazione dei dati e distribuzione delle variabili**  \n2. **Visualizzazione e confronto tra gruppi**  \n3. **Analisi delle possibili associazioni tra SWLS e le componenti della rete sociale**\n\n**Parte 1: Esplorazione dei Dati**\n\n**1.1 Caricamento e preparazione del dataset**\n\n1. Importa il dataset `swls_lsns_students.csv`.  \n2. Seleziona le variabili indicate sopra.  \n3. Controlla ed elimina eventuali duplicati.  \n4. Controlla ed elimina eventuali valori mancanti.  \n\n```r\n# Caricamento del dataset\ndf <- rio::import(here::here(\"data\", \"swls_lsns_students.csv\"))\n\n# Selezione delle variabili\ndf <- df |> dplyr::select(student_id, group, swls, gender, \n                          lsns_total, lsns_family, lsns_friends)\n\n# Rimozione dei duplicati\ndf <- df[!duplicated(df$student_id), ]\n\n# Rimozione dei valori mancanti\ndf <- df[complete.cases(df), ]\n```\n\n**1.2 Distribuzione delle variabili** \n\n5. Calcola la **distribuzione di frequenza** per `swls`, `lsns_total`, `lsns_family` e `lsns_friends`:\n   - Frequenze assolute e relative  \n   - Frequenze cumulative  \n\n```r\n# Frequenze assolute e relative\ntable(df$swls)\nprop.table(table(df$swls))\n\ntable(df$lsns_total)\nprop.table(table(df$lsns_total))\n```\n\n6. Crea un **istogramma** della distribuzione delle variabili.\n\n```r\nggplot(df, aes(x = swls)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione dei punteggi SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"Frequenza\")\n```\n\n```r\nggplot(df, aes(x = lsns_total)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione dei punteggi LSNS-6 (totale)\",\n       x = \"Punteggio LSNS-6\",\n       y = \"Frequenza\")\n```\n\n7. Costruisci la **funzione di distribuzione empirica cumulativa (eCDF)**.\n\n```r\nggplot(df, aes(x = swls)) +\n  stat_ecdf(geom = \"step\", color = \"blue\") +\n  labs(title = \"Funzione di distribuzione empirica cumulativa SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"F(x)\")\n```\n\n8. Genera la **curva di densità kernel (KDE)** per ogni variabile.\n\n```r\nggplot(df, aes(x = swls)) +\n  geom_density(fill = \"lightblue\", alpha = 0.5) +\n  labs(title = \"Curva di densità dei punteggi SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"Densità\")\n```\n\n```r\nggplot(df, aes(x = lsns_total)) +\n  geom_density(fill = \"lightblue\", alpha = 0.5) +\n  labs(title = \"Curva di densità LSNS-6 (totale)\",\n       x = \"Punteggio LSNS-6\",\n       y = \"Densità\")\n```\n\n**Parte 2: Confronto tra Gruppi**\n\n9. Costruisci una **tabella di contingenza** per `gender` e livello di rete sociale (alta o bassa, separando sopra e sotto la mediana di `lsns_total`).\n\n```r\ndf <- df |> \n  mutate(lsns_level = ifelse(lsns_total >= median(lsns_total), \"Alto\", \"Basso\"))\n\ntable(df$gender, df$lsns_level)\nprop.table(table(df$gender, df$lsns_level), margin = 1)\n```\n\n10. Crea un **grafico a barre** per la distribuzione di `lsns_level` per genere.\n\n```r\nggplot(df, aes(x = lsns_level, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Distribuzione del livello di rete sociale per genere\",\n       x = \"Livello LSNS\",\n       y = \"Conteggio\",\n       fill = \"Genere\")\n```\n\n11. Costruisci un **box plot** per confrontare `swls` tra i gruppi di rete sociale.\n\n```r\nggplot(df, aes(x = lsns_level, y = swls, fill = lsns_level)) +\n  geom_boxplot() +\n  labs(title = \"Distribuzione dei punteggi SWLS per livello di rete sociale\",\n       x = \"Livello di rete sociale\",\n       y = \"Punteggio SWLS\")\n```\n\n12. Usa un **violin plot** per visualizzare la distribuzione dettagliata.\n\n```r\nggplot(df, aes(x = lsns_level, y = swls, fill = lsns_level)) +\n  geom_violin(alpha = 0.5) +\n  geom_jitter(width = 0.1, alpha = 0.5) +\n  labs(title = \"Violin plot con dati grezzi sovrapposti\",\n       x = \"Livello di rete sociale\",\n       y = \"Punteggio SWLS\")\n```\n\n**Parte 3: Analisi delle Associazioni tra SWLS e la Rete Sociale**\n\nIl concetto di correlazione verrà approfondito nel @sec-correlation. Per i nostri scopi attuali, possiamo considerarlo come un indice numerico che misura l'intensità e la direzione dell'associazione tra due variabili. Un valore di 0 indica l'assenza di una relazione lineare tra le variabili, mentre i valori +1 e -1 indicano una relazione lineare perfetta, positiva o negativa rispettivamente. I valori intermedi tra -1 e +1 rappresentano associazioni più deboli o forti, a seconda della loro vicinanza agli estremi.\n\n13. **Correlazioni** tra SWLS e le sottoscale della LSNS.\n\n```r\ncor(df$swls, df$lsns_total, method = \"pearson\")\ncor(df$swls, df$lsns_family, method = \"pearson\")\ncor(df$swls, df$lsns_friends, method = \"pearson\")\n```\n\nSpiega in maniera inuitiva il significato dei valori ottenuti.\n\n14. **Grafico di dispersione** tra SWLS e LSNS-6 totale.\n\nUn grafico di dispersione è un diagramma cartesiano in cui ogni punto rappresenta un'osservazione (nel caso attuale, uno studente). Le coordinate dei punti sui due assi, X e Y, indicano i valori delle due variabili considerate per ciascuno studente.\n\n```r\nggplot(df, aes(x = lsns_total, y = swls)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Relazione tra rete sociale totale e SWLS\",\n       x = \"Punteggio LSNS-6 Totale\",\n       y = \"Punteggio SWLS\")\n```\n\nPer ogni grafico generato, includi una descrizione chiara e concisa del suo significato in relazione ai dati analizzati.\n\n**Conclusioni**\n\nL'obiettivo è analizzare se e come la **soddisfazione di vita** degli studenti universitari è influenzata dalle **relazioni sociali**, distinguendo tra **engagement con la famiglia e con gli amici**. \n\n**Consegna**\n\nConsegna il file `.qmd` contenente il codice, le visualizzazioni e le interpretazioni.\n:::\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] viridis_0.6.5         viridisLite_0.4.2     cowplot_1.2.0        \n#>  [4] ggpubr_0.6.1          gridExtra_2.3         dslabs_0.8.0         \n#>  [7] ggbeeswarm_0.7.2      pillar_1.11.0         tinytable_0.13.0     \n#> [10] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#> [13] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [16] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [19] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [22] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [25] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [28] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [31] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] inline_0.3.21         sandwich_3.1-1        rlang_1.1.6          \n#>  [4] magrittr_2.0.3        multcomp_1.4-28       snakecase_0.11.1     \n#>  [7] compiler_4.5.1        systemfonts_1.2.3     vctrs_0.6.5          \n#> [10] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#> [13] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#> [16] rmarkdown_2.29        ragg_1.5.0            purrr_1.1.0          \n#> [19] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#> [22] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#> [25] stringi_1.8.7         RColorBrewer_1.1-3    car_3.1-3            \n#> [28] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#> [31] zoo_1.8-14            R.utils_2.13.0        pacman_0.5.1         \n#> [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#> [37] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#> [40] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#> [43] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#> [46] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#> [49] carData_3.0-5         tensorA_0.36.2.1      checkmate_2.3.3      \n#> [52] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#> [55] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#> [58] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#> [61] tools_4.5.1           data.table_1.17.8     ggsignif_0.6.4       \n#> [64] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#> [67] colorspace_2.1-1      nlme_3.1-168          beeswarm_0.4.0       \n#> [70] vipor_0.4.7           Formula_1.2-5         cli_3.6.5            \n#> [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#> [76] V8_7.0.0              gtable_0.3.6          R.methodsS3_1.8.2    \n#> [79] rstatix_0.7.2         digest_0.6.37         TH.data_1.1-4        \n#> [82] htmlwidgets_1.6.4     farver_2.1.2          R.oo_1.27.1          \n#> [85] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#> [88] MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n",
    "supporting": [
      "04_exploring_numeric_data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}