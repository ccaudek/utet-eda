{
  "hash": "b38071fc7a1c840d9e0944dc393b7405",
  "result": {
    "engine": "knitr",
    "markdown": "# Outlier {#sec-eda-outlier}\n\n::: {.epigraph}\n> “Statisticians, like artists, have the bad habit of falling in love with their models. Outliers are the rude reminders that reality is less tidy than our assumptions.”\n>\n> -- **George E. P. Box** \n:::\n\n\n## Introduzione {.unnumbered .unlisted}\n\nQuando analizziamo dati reali, ci imbattiamo spesso in osservazioni che sembrano molto diverse dalla maggior parte delle altre. Questi valori anomali, chiamati *outlier*, possono avere origini diverse. Ad esempio, potrebbero derivare da errori di misura o inserimento dati, oppure essere casi estremi ma comunque validi.\n\nIdentificare e trattare gli outlier in modo appropriato è importante per evitare che distorcano i risultati dell'analisi. Tuttavia, non esiste una definizione universale di outlier: dipende dal contesto e dall'obiettivo dell'analisi. In questo capitolo, esploreremo diversi metodi per individuare gli outlier, concentrandoci su tecniche robuste che minimizzano l'influenza di questi valori anomali sulle statistiche descrittive [@simmons2011false].\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- comprendere il ruolo e gli effetti degli outlier;\n- individuare outlier con metodi univariati e multivariati;\n- utilizzare il pacchetto {performance} in R per rilevarli;\n- documentare e rendere riproducibili le procedure;\n- considerare alternative (es. winsorizzazione) e preregistrare le scelte.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere \"Check your outliers! An introduction to identifying statistical outliers in R with easystats\" [@theriault2024check].\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(performance, see, datawizard, MASS)\n```\n:::\n\n:::\n\n\n## Individuare e gestire gli outlier\n\nIdentificare ed eventualmente eliminare gli outlier rappresenta una fase cruciale dell'analisi dei dati, poiché la presenza di valori anomali può influenzare fortemente le conclusioni che si traggono da analisi statistiche. Gli outlier possono infatti alterare notevolmente statistiche descrittive come media e deviazione standard, ma anche misure di relazione come correlazioni e regressioni. Ciò avviene perché molte tecniche statistiche comuni (ad esempio, la media aritmetica o la regressione lineare con metodo dei minimi quadrati) sono particolarmente sensibili ai valori estremi.\n\nAd esempio, se stiamo analizzando il reddito medio di un gruppo di persone e includiamo erroneamente dati di reddito estremamente elevati o inseriti per errore, la media risultante sarà molto più alta del reale valore tipico del gruppo, producendo una rappresentazione fuorviante della situazione.\n\n### L'importanza della visualizzazione dei dati  \n\nLa rappresentazione grafica dei dati è uno strumento fondamentale per individuare rapidamente la presenza di outlier. Grafici come boxplot, istogrammi e scatterplot consentono di identificare visivamente valori anomali che si discostano dalla distribuzione generale.  Tuttavia, queste tecniche sono efficaci principalmente per outlier unidimensionali o bidimensionali. Nel caso di outlier multidimensionali, l’analisi visiva diventa insufficiente e si rende necessario l’utilizzo di metodi statistici più avanzati, come il calcolo della distanza di Mahalanobis.\n\n## Come identificare gli outlier\n\nOltre alla visualizzazione grafica, esistono tecniche statistiche specifiche che consentono di identificare gli outlier in modo sistematico.\n\n### I boxplot\n  \n  Uno strumento semplice e intuitivo per individuare gli outlier è il *boxplot*. Il boxplot riassume la distribuzione di una variabile mostrando la mediana, il primo e il terzo quartile (Q1 e Q3) e due estremi, detti \"whiskers\". I punti al di fuori di questi whiskers sono considerati potenziali outlier.\n\nEsempio in R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata <- data.frame(\n  value = c(rnorm(100, mean = 10, sd = 2), 30)\n  ) # Aggiungiamo un outlier\n\nggplot(data, aes(y = value)) +\n  geom_boxplot() +\n  coord_flip()\n```\n\n::: {.cell-output-display}\n![](10_outlier_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nSe il boxplot mostra un punto isolato lontano dagli altri dati, potrebbe essere un outlier.\n\n### Metodi basati sulla variabilità\n\n#### Intervallo interquartile (IQR)\n\nJohn Tukey ha introdotto una definizione operativa di outlier basata sull'*Interquartile Range* (IQR), ovvero la differenza tra il terzo e il primo quartile:\n\n- I valori inferiori a $Q1 - 1.5 \\times IQR$ o superiori a $Q3 + 1.5 \\times IQR$ sono considerati outlier moderati.\n- I valori oltre $Q1 - 3 \\times IQR$ o $Q3 + 3 \\times IQR$ sono definiti *far out* outliers.\n\nEsempio in R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nQ1 <- quantile(data$value, 0.25)\nQ3 <- quantile(data$value, 0.75)\nIQR_value <- Q3 - Q1\nlower_bound <- Q1 - 1.5 * IQR_value\nupper_bound <- Q3 + 1.5 * IQR_value\n\noutliers <- data$value[data$value < lower_bound | data$value > upper_bound]\noutliers\n#> [1] 30\n```\n:::\n\n\nQuesto metodo è efficace per distribuzioni simmetriche, ma potrebbe non funzionare bene con dati asimmetrici.\n\n\n#### Median Absolute Deviation (MAD)\n\nUn metodo più robusto rispetto all'IQR è il *Median Absolute Deviation* (MAD), che utilizza la mediana anziché la media per stimare la dispersione:\n  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmad_value <- mad(data$value)\nthreshold <- 3 * mad_value # Soglia classica per gli outlier\n\noutliers_mad <- data$value[abs(data$value - median(data$value)) > threshold]\noutliers_mad\n#> [1] 30\n```\n:::\n\n\nIl MAD è meno sensibile agli outlier rispetto alla deviazione standard ed è spesso preferito per dati con distribuzioni non normali.\n\n## Outlier multivariati\n\nQuando si considerano più variabili contemporaneamente, un valore potrebbe non apparire anomalo su una singola variabile, ma esserlo nel contesto dell'intero dataset. Un metodo comune per individuare questi outlier è la *Distanza di Mahalanobis*, che tiene conto delle correlazioni tra variabili.\n\n- Con la distanza \"normale\" (come quella che misuri con un righello), se una persona è più alta o più pesante della media, la distanza è calcolata in modo \"isolato\", senza considerare che altezza e peso sono spesso correlate (persone più alte tendono a pesare di più).\n- Con la distanza di Mahalanobis, invece, si osserva il \"contesto\" dei dati. Se tutti nel gruppo hanno un’altezza e un peso che crescono in modo coordinato (ad esempio, ogni 10 cm in più corrispondono a 8 kg in più), questa distanza valuta se la nuova persona si allontana da questo schema generale. Ad esempio, una persona molto alta ma con peso medio potrebbe essere considerata più \"anomala\" di una persona altrettanto alta ma più pesante, perché viola la relazione tipica del gruppo.\n\nPer comprendere intuitivamente la distanza di Mahalanobis, immaginiamo di avere una nube di punti che rappresentano individui, ciascuno con i propri valori di altezza e peso. Il “centro” di questa nube è un punto ideale che rappresenta una sorta di media multivariata (tenendo conto sia dell’altezza sia del peso). La distanza di Mahalanobis misura quanto ogni singolo individuo si allontana da questo centro, considerando la variabilità congiunta delle variabili (ad esempio, la correlazione tra altezza e peso). Se un individuo presenta caratteristiche molto diverse rispetto alla maggioranza, la sua distanza di Mahalanobis sarà elevata, segnalando un potenziale outlier.\n\n::: {#fig-maha-dist}\n![](../../figures/outliers.png){width=\"70%\"}\n\n**Soglie per la detezione degli outliers** (bande grigie) nel caso di una metrica unidimensionale (pannello di sinistra) e nel caso di una rappresentazione multivariata della varianza (pannello di destra) -- figura creata da Sergen Cansiz.\n:::\n\n::: {.callout-tip title=\"Distanza di Mahalanobis\" collapse=\"true\"}\nConsideriamo ora una definizione della distanza di Mahalanobis nel caso bivariato (due variabili). Immaginiamo di avere due variabili come altezza ($X$) e peso ($Y$), con:  \n\n- **Medie**: $\\mu_X$ (altezza media del gruppo), $\\mu_Y$ (peso medio del gruppo).  \n- **Varianze**: $\\sigma_X^2$ (quanto varia l'altezza), $\\sigma_Y^2$ (quanto varia il peso).  \n- **Correlazione**: $\\rho$ (quanto $X$ e $Y$ sono legate, ad esempio: se l'altezza aumenta, di quanto aumenta solitamente il peso?).\n\n**Per un nuovo individuo** con altezza $x$ e peso $y$, la distanza di Mahalanobis ($D$) si calcola così:  \n\n1. **Calcolare le differenze rispetto alla media**:  \n   - Quanto si discosta l'altezza: $(x - \\mu_X)$.\n   - Quanto si discosta il peso: $(y - \\mu_Y)$. \n\n2. **Scalare le differenze con le varianze**:  \n   - Dividere ogni differenza per la sua \"variabilità tipica\" (deviazione standard $\\sigma_X$ e $\\sigma_Y$):  \n   \n     $$\n     \\frac{(x - \\mu_X)}{\\sigma_X} \\quad \\text{e} \\quad \\frac{(y - \\mu_Y)}{\\sigma_Y} .\n     $$\n\n3. **Correggere per la correlazione**:  \n\n   - Se $X$ e $Y$ sono correlate ($\\rho \\neq 0$), modifica le differenze per tenere conto di come di solito si \"muovono insieme\".  \n   - La formula finale combina tutto in un unico valore:  \n     $$\n     D = \\sqrt{ \\frac{ \\left( \\frac{(x - \\mu_X)}{\\sigma_X} \\right)^2 + \\left( \\frac{(y - \\mu_Y)}{\\sigma_Y} \\right)^2 - 2 \\rho \\left( \\frac{(x - \\mu_X)}{\\sigma_X} \\right)\\left( \\frac{(y - \\mu_Y)}{\\sigma_Y} \\right) }{1 - \\rho^2} }\n     $$\n     \n**Spiegazione**:  \n\n- Senza correlazione ($\\rho = 0$), sarebbe come una distanza Euclidea \"scalata\" dalle varianze.  \n- Con correlazione ($\\rho \\neq 0$), sottrai un termine che \"aggiusta\" la distanza in base a quanto $X$ e $Y$ tendono a variare insieme.  \n- Il denominatore $1 - \\rho^2$ normalizza il risultato, per evitare che la correlazione distorca troppo la misura.  \n\n**Esempio**:  \nSe tutti gli alti sono anche pesanti ($\\rho$ positivo), un individuo alto ma magro avrà una distanza di Mahalanobis maggiore rispetto a uno altrettanto alto ma pesante, perché viola la relazione tipica del gruppo.  \n:::\n\n::: {.callout-tip title=\"Distanza Eucliea\" collapse=\"true\"}\nRicordiamo che la distanza euclidea tra due punti $(x_1, y_1)$ e $(x_2, y_2)$ in un piano cartesiano è definita come:\n\n$$ \nd = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} \n$$\n:::\n\nEsempio in R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nX <- as.matrix(mtcars[, c(\"mpg\", \"hp\")])\ncenter <- colMeans(X)\ncov_matrix <- cov(X)\nmahal_dist <- mahalanobis(X, center, cov_matrix)\n\nthreshold <- qchisq(0.975, df = ncol(X)) # Soglia al 97.5%\noutliers_mahal <- X[mahal_dist > threshold, ]\noutliers_mahal\n#> mpg  hp \n#>  15 335\n```\n:::\n\n\nQuesto metodo è utile per dataset con più variabili correlate, come misure biometriche (altezza e peso).\n\nTuttavia, la versione classica di questa misura non è particolarmente robusta: la presenza stessa di outlier può distorcere il calcolo del “centro” e della variabilità complessiva, rendendo meno affidabile l’individuazione di altri valori anomali. Per questo motivo, si preferisce utilizzare una variante più resistente, la Minimum Covariance Determinant (MCD), che diminuisce l’influenza degli outlier stessi nel processo di identificazione.\n\nAll’interno del pacchetto {performance} in R, è possibile applicare questa variante robusta utilizzando la funzione `check_outliers()` con l’argomento `method = \"mcd\"`. In questo modo, è possibile individuare gli outlier multivariati in maniera più solida e coerente, anche quando si lavora con dati fortemente influenzati da valori estremi.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd <- mtcars[, c(\"mpg\", \"hp\")]\noutliers <- performance::check_outliers(d, method = \"mcd\", verbose = FALSE)\noutliers\n#> 2 outliers detected: cases 20, 31.\n#> - Based on the following method and threshold: mcd (13.816).\n#> - For variables: mpg, hp.\n```\n:::\n\n\nSi possono poi visualizzare questi outlier:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(outliers)\n```\n\n::: {.cell-output-display}\n![](10_outlier_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nSono disponibili anche altre varianti multivariate documentate nella help page della funzione.\n\n\n## Cosa fare con gli outlier?\n\nUna volta identificati gli outlier, dobbiamo decidere se rimuoverli, correggerli o mantenerli [@leys2019classify]. Alcuni approcci comuni includono:\n\n1. **Verificare la fonte del dato**: un errore di inserimento può essere corretto.\n2. **Rimuovere gli outlier estremi**: utile se il valore è chiaramente un errore di misura.\n3. **Usare metodi robusti**: strumenti come la mediana o il MAD sono meno influenzati dagli outlier.\n4. **Trasformare i dati**: applicare logaritmi o altre trasformazioni può ridurre l'impatto degli outlier.\n5. **Winsorizzazione**: invece di rimuovere gli outlier, possiamo limitarli a un massimo accettabile.\n\n::: {.callout-tip title=\"Winsorizzazione\" collapse=\"true\"}\nNella Winsorizzazione, invece di eliminare gli outlier, si sostituiscono i valori troppo alti o troppo bassi con i valori più vicini considerati \"accettabili\", mantenendo però la struttura generale dei dati.\n\n**Come funziona?**  \n1. **Definisci i limiti**:  \n\n   - Decidi una \"soglia\" per identificare gli outlier, ad esempio il **5° percentile** (valore sotto cui cade il 5% dei dati più bassi) e il **95° percentile** (valore sopra cui cade il 5% dei dati più alti).  \n   - Queste soglie dipendono dal contesto: puoi usare percentili diversi (es. 1° e 99°) in base a quanto vuoi essere severo nel definire gli outlier.\n\n2. **Sostituisci gli outlier**:  \n\n   - **Valori troppo bassi**: Tutti i dati sotto il 5° percentile vengono sostituiti con il valore del 5° percentile.  \n   - **Valori troppo alti**: Tutti i dati sopra il 95° percentile vengono sostituiti con il valore del 95° percentile.  \n\n**Esempio concreto**:  \nSupponiamo di avere i seguenti dati su 10 esami (ordinati):  \n`40, 55, 60, 65, 70, 75, 80, 85, 90, 200`  \n\n- **5° percentile**: 55 (il valore sotto cui cade il 5% dei dati).  \n- **95° percentile**: 90 (il valore sopra cui cade il 5% dei dati).  \n\n**Dopo la Winsorizzazione**:  \n- Il valore più basso (40) diventa 55.  \n- Il valore più alto (200) diventa 90.  \nNuovi dati: `55, 55, 60, 65, 70, 75, 80, 85, 90, 90`.\n\n**Perché usarla?**  \n\n- **Mantiene la dimensione del dataset**: Non si eliminano dati, ma si modificano solo gli outlier. \n- **Riduce la distorsione**: Gli outlier estremi non \"trascinano\" la media o altre statistiche.  \n- **Utile in contesti sensibili**: Ad esempio, in finanza (per gestire rendimenti anomali) o nelle analisi mediche (per evitare che valori estremi falsino i risultati).\n:::\n\nNel pacchetto **easystats**, la funzione `winsorize()` di **datawizard** semplifica il compito di Winsorizzazione:\n  \n```r\nwinsorized_data <- \n  winsorize(data$value, method = \"zscore\", robust = TRUE, threshold = 3)\n```\n\n## Importanza della trasparenza\n\nQualunque decisione va documentata chiaramente: quanti outlier sono stati individuati, con quale metodo, a quale threshold, come sono stati gestiti, e preferibilmente con il codice R utilizzato. La preregistrazione e la condivisione dei dati e del codice (ad es. su OSF) sono pratiche consigliate per garantire riproducibilità e trasparenza.\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nAbbiamo mostrato come identificare gli outlier in modo coerente e trasparente, allineandoci alle buone pratiche correnti. Tuttavia, la buona pratica non si limita alla scelta degli algoritmi: è fondamentale anche preregistrare le decisioni, essere coerenti, trasparenti e fornire giustificazioni. \n\n\n::: {.callout-important title=\"Problemi 1\" collapse=\"true\"}\n**Domande teoriche**\n\n1. Cos'è un outlier?\n2. Perché è importante identificare e trattare correttamente gli outlier?\n3. Descrivi brevemente il metodo del boxplot per identificare gli outlier.\n4. Cosa si intende per Interquartile Range (IQR) e come viene utilizzato per individuare gli outlier?\n5. Qual è la differenza tra il metodo IQR e il Median Absolute Deviation (MAD) per l'identificazione degli outlier?\n6. Cos'è la distanza di Mahalanobis e in che modo può aiutare nell'identificazione degli outlier multivariati?\n7. Perché la distanza di Mahalanobis classica potrebbe non essere robusta? Come si può migliorare l'approccio?\n8. Quali sono le opzioni per gestire gli outlier una volta identificati?\n9. Cos'è la Winsorizzazione e in quali casi potrebbe essere utile?\n10. Perché è importante la trasparenza nelle decisioni riguardanti gli outlier?\n:::\n\n::: {.callout-tip title=\"Soluzioni 1\" collapse=\"true\"}\n1. **Cos'è un outlier?**\n\n   - Un outlier è un'osservazione che si discosta significativamente dalla maggior parte delle altre osservazioni in un insieme di dati. Può essere dovuto ad errori di misura, errori di inserimento dati o a casi estremi ma validi.\n\n2. **Perché è importante identificare e trattare correttamente gli outlier?**\n\n   - Gli outlier possono distorcere i risultati dell'analisi statistica, portando a conclusioni errate. Identificarli e trattarli correttamente aiuta a ridurre l'effetto di questi valori anomali sulle statistiche descrittive e sulle inferenze statistiche.\n\n3. **Descrivi brevemente il metodo del boxplot per identificare gli outlier.**\n\n   - Il boxplot visualizza la distribuzione di una variabile, mostrando la mediana, il primo e il terzo quartile, e due estremi (\"whiskers\"). I punti al di fuori di questi whiskers sono considerati potenziali outlier.\n\n4. **Cosa si intende per Interquartile Range (IQR) e come viene utilizzato per individuare gli outlier?**\n\n   - L'IQR è la differenza tra il terzo e il primo quartile di un insieme di dati. Valori inferiori a $Q1 - 1.5 \\times IQR$ o superiori a $Q3 + 1.5 \\times IQR$ sono considerati outlier moderati. Valori oltre $Q1 - 3 \\times IQR$ o $Q3 + 3 \\times IQR$ sono definiti \"far out\" outliers.\n\n5. **Qual è la differenza tra il metodo IQR e il Median Absolute Deviation (MAD) per l'identificazione degli outlier?**\n\n   - Il metodo IQR si basa sulla differenza tra il terzo e il primo quartile, mentre il MAD utilizza la mediana delle deviazioni assolute dalla mediana per stimare la dispersione. Il MAD è meno sensibile agli outlier rispetto all'IQR e alla deviazione standard, rendendolo preferibile per dati con distribuzioni non normali.\n\n6. **Cos'è la distanza di Mahalanobis e in che modo può aiutare nell'identificazione degli outlier multivariati?**\n\n   - La distanza di Mahalanobis misura quanto un punto si discosta dal centro della distribuzione di un set di dati multivariato, tenendo conto della correlazione tra le variabili. Valori con distanze di Mahalanobis elevate sono potenziali outlier multivariati.\n\n7. **Perché la distanza di Mahalanobis classica potrebbe non essere robusta? Come si può migliorare l'approccio?**\n\n   - La distanza di Mahalanobis classica può essere distorta dalla presenza di outlier, che influenzano il calcolo del centro e della variabilità complessiva. Un approccio più robusto è la Minimum Covariance Determinant (MCD), che riduce l'influenza degli outlier nel processo di identificazione.\n\n8. **Quali sono le opzioni per gestire gli outlier una volta identificati?**\n\n   - Le opzioni includono: verificare la fonte del dato per possibili errori, rimuovere gli outlier estremi, usare metodi robusti come la mediana o il MAD, trasformare i dati (ad esempio, logaritmi), e limitare gli outlier attraverso la Winsorizzazione.\n\n9. **Cos'è la Winsorizzazione e in quali casi potrebbe essere utile?**\n\n   - La Winsorizzazione è una tecnica che consiste nel sostituire gli outlier estremi con il valore massimo o minimo accettabile. È utile quando si vuole mantenere la dimensione del dataset e ridurre l'impatto degli outlier senza rimuoverli completamente.\n\n10. **Perché è importante la trasparenza nelle decisioni riguardanti gli outlier?**\n\n  - La trasparenza aiuta a garantire la riproducibilità e la validità dell'analisi. Documentare le decisioni, inclusi i metodi e i threshold utilizzati, consente ad altri di capire e valutare l'impatto di queste decisioni sui risultati dell'analisi.\n:::\n\n::: {.callout-important title=\"Problemi 2\" collapse=\"true\"}\n**Esercizio: Gestione degli Outlier nella Scala di Soddisfazione di Vita (SWLS)**\n\n**Scopo:**  \nImparare a individuare e correggere gli outlier in un dataset che misura la soddisfazione di vita (SWLS). L’esercizio prevede l’inserimento artificiale di due outlier (uno molto alto e uno molto basso) nei dati raccolti, per poi gestirli con i metodi discussi nel capitolo. Infine, bisognerà consegnare:\n\n1. Un file `.qmd` (Quarto) con tutto il codice e i commenti delle operazioni svolte.  \n2. Un file CSV finale con i dati “puliti” (ossia senza i due outlier anomali) o con i valori modificati mediante il metodo scelto (winsorizzazione, rimozione, correzione, ecc.).\n\n**Fasi e Istruzioni**\n\n1. **Scarica o carica il dataset SWLS**  \n   - Nominare il dataset originale, ad esempio *SWLS_raw.csv*, contenente i punteggi dei partecipanti sulla Scala di Soddisfazione di Vita (SWLS).  \n   - Assicurati di avere nel dataset almeno le colonne:  \n     - `id` (identificatore univoco del partecipante)  \n     - `swls_score` (punteggio totale alla scala SWLS)\n\n2. **Crea due outlier artificiali**  \n   - Scegli **un partecipante** al quale assegnare un valore estremamente **basso** di `swls_score` (es. -999) e **un altro partecipante** con un valore estremamente **alto** (es. 999).  \n   - Spiega brevemente nel `.qmd` dove e come hai inserito questi valori.  \n\n3. **Analizza i dati alla ricerca di outlier**  \n   - Visualizza la distribuzione tramite un boxplot e/o un istogramma.  \n   - Calcola i valori soglia utilizzando **almeno uno** dei metodi visti:  \n     - IQR (intervallo interquartile)  \n     - MAD (Median Absolute Deviation)  \n   - Mostra quali osservazioni vengono segnalate come potenziali outlier.  \n\n4. **Decidi come gestire gli outlier**  \n   - Scegli se rimuoverli, winsorizzarli o correggerli.  \n   - Giustifica la tua scelta: spiega perché quel metodo è appropriato per questi dati o perché preferisci un approccio rispetto a un altro.\n\n5. **Genera i dati “puliti”**  \n   - Applica il metodo selezionato.  \n   - Salva il dataset risultante (senza i valori anomali o con i valori modificati) in un file CSV chiamato *SWLS_clean.csv*.  \n\n6. **Documenta tutto in un file `.qmd`**  \n   - Includi codice R, commenti e brevi spiegazioni testuali dei vari passaggi.  \n   - Mostra i risultati rilevanti (boxplot, calcolo dei soglie IQR/MAD, elenco degli outlier individuati, ecc.).  \n   - Assicurati di eseguire il rendering del `.qmd` in modo che l’istruttore possa vedere sia l’output che il codice.\n\n7. **Consegnare i file**  \n   - **File .qmd**: deve contenere tutto il codice e i passaggi effettuati (inclusi grafici, calcoli e spiegazioni).  \n   - **File CSV “pulito”** (*SWLS_clean.csv*): con i dati finali dopo il trattamento degli outlier.\n\n**Suggerimenti**\n\n- **Struttura** il tuo `.qmd` in sezioni (ad es. *Caricamento dati*, *Creazione outlier artificiali*, *Identificazione outlier*, *Gestione outlier*, *Salvataggio dati puliti*).  \n- **Motiva** sempre le scelte, soprattutto se rimuovi o modifichi i dati originali: spiega perché il valore appare come un errore di misura o un valore estremo.  \n- **Fai controlli incrociati**: potresti usare più di un metodo (boxplot, IQR, MAD) per vedere se l’outlier viene segnalato in tutti i casi.  \n- **Documenta** la tua strategia di trasparenza nell’analisi: note sull’eventuale preregistrazione di come avresti gestito gli outlier o su come hai deciso i threshold.\n:::\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] MASS_7.3-65           datawizard_1.2.0      see_0.11.0           \n#>  [4] performance_0.15.1    pillar_1.11.0         tinytable_0.13.0     \n#>  [7] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#> [10] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [13] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [16] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [19] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [22] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [25] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [28] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#> [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#> [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#> [16] labeling_0.4.3        rmarkdown_2.29        ragg_1.5.0           \n#> [19] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#> [22] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#> [25] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#> [28] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#> [31] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#> [34] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#> [37] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#> [40] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#> [43] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#> [46] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#> [49] checkmate_2.3.3       stats4_4.5.1          insight_1.4.2        \n#> [52] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#> [55] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#> [58] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#> [61] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#> [64] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#> [67] textshaping_1.0.3     svUnit_1.0.8          viridisLite_0.4.2    \n#> [70] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#> [73] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#> [76] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#> [79] lifecycle_1.0.4\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n",
    "supporting": [
      "10_outlier_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}